{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# File paths\n",
    "DATA_FP = \"./data/\" # Data file path\n",
    "TWEETS_FP = DATA_FP + \"tweets.json\"\n",
    "TRAIN_DEV_FP = DATA_FP + \"labels-train+dev.tsv\"\n",
    "TEST_FP = DATA_FP + \"labels-test.tsv\"\n",
    "\n",
    "# Column names\n",
    "COL_ID = 'ID'\n",
    "COL_TWEET = 'Tweet'\n",
    "COL_LABEL = 'Label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data\n",
    "\n",
    "## Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the first file (Tweets)\n",
    "tweets = []\n",
    "with open(TWEETS_FP, 'r') as tweets_fh:  # Tweets file handle\n",
    "    for line in tweets_fh:   # put each line in a list of lines\n",
    "        j_content = json.loads(line)\n",
    "        tweets.append(j_content)\n",
    "\n",
    "tweets = pd.DataFrame(tweets, columns=[COL_ID, COL_TWEET])  # make a dataframe out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483885347374243841</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø£ÙØ±Ø­ Ù‚Ù„Ø¨ÙŠ ÙˆÙ‚Ù„Ø¨ Ù…Ù† Ø£Ø­Ø¨ ÙˆØ£ØºØ³Ù„ Ø£Ø­Ø²Ø§Ù†Ù†Ø§ ÙˆÙ‡Ù…Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484023414781263872</td>\n",
       "      <td>Ø¥Ø¶ØºØ· Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚ØªÙƒ ÙŠØªØ¨ÙŠÙ† Ù„Ùƒ ÙƒÙ… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª Ø¹Ù† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484026168300273664</td>\n",
       "      <td>Ø§Ù„Ù„ÙÙ‘Ù‡ÙŒÙ…ÙÙ‘ ØµÙÙ„ÙÙ‘ ÙˆÙØ³ÙÙ„ÙÙ‘Ù…Ù’ Ø¹ÙÙ„Ù‰Ù° Ù†ÙØ¨ÙÙŠÙÙ‘Ù†ÙØ¢ Ù…Ù...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483819942878650369</td>\n",
       "      <td>@Dinaa_ElAraby Ø§Ù‡Ø§ ÙŠØ§ Ø¨ÙŠØ¨ÙŠ ÙˆØ§Ù„Ù„Ù‡ Ø§ØªÙ‡Ø±Ø³Øª Ø¹Ù„ÙŠ ØªÙˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>483793769079123971</td>\n",
       "      <td>â€¢ Ø§ÙØ¶Ù„ ÙƒØªØ§Ø¨ Ù‚Ø±Ø£ØªÙ‡ Ù‡Ùˆ : Ø£Ù…ÙŠ (Ø§Ø¨Ø±Ø§Ù‡Ø§Ù… Ù„Ù†ÙƒÙˆÙ„Ù†)\\nğŸŒ¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>483934868070350849</td>\n",
       "      <td>@hudc7721 Ø§Ù†ØªØ¸Ø±ÙŠ Ø§Ø¬Ù„ \\nØ®ÙŠØ±Ù‡ Ù„Ùƒ ÙŠØ§Ø±Ø¨ ğŸ˜˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>483863369972473856</td>\n",
       "      <td>(ÙˆØ¥Ù† ØªØ¬Ù‡Ø± Ø¨Ø§Ù„Ù‚ÙˆÙ„ ÙØ¥Ù†Ù‡ ÙŠØ¹Ù„Ù… Ø§Ù„Ø³Ø± ÙˆØ£Ø®ÙÙ‰) [Ø·Ù‡:7]\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>483871567311413248</td>\n",
       "      <td>ïº§ï»ŸÙƒ ï»‹Ø²ï¯¾Ø² Ø¢ï»Ÿï»§ï»“Ø³ ï»ŸÛˆ ï®ªï»£Ûˆï»£Ùƒ ïºŸïº‘Ø¢Ù„Ù„Ø§ï­ ïº·ïº·ï®ÙŠ ï»Ÿï»Ÿï»§Ø¢ïº³Ø³ ï»£Ù† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>483931429902884864</td>\n",
       "      <td>Ø¹Ø´Ø§Ù† Ø§Ù„Ø¬Ù†Ù‘Ø© Ø£Ø¬Ù…Ù„ ØŸ  Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø¹Ø¯Ù†Ø§ Ø¹Ù† ÙƒÙ„ Ø°Ù†Ø¨ Ù…Ø§ÙŠØ®...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>483773756897124352</td>\n",
       "      <td>ØªÙˆØ¬ÙŠÙ‡ ÙƒÙŠÙÙŠØ© ØªØ«Ø¨ÙŠØª Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ø«Ø§Ø¨ØªØ© ROM Ø§Ù„ØªØ­Ù…ÙŠÙ„ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>483986544865210368</td>\n",
       "      <td>@dana_mahmod Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø­ÙƒÙŠÙƒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>483873243598565376</td>\n",
       "      <td>@anabs_anabs @Rayedrd Ø£Ù†Ø´Ù‡Ø¯ Ø¨Ø³ ÙÙŠÙ‡ Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ø§Ø³ Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>483790646176935936</td>\n",
       "      <td>{ÙŠØ¹Ù„Ù…ÙˆÙ† Ø¸Ø§Ù‡Ø±Ø§ Ù…Ù† Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆÙ‡Ù… Ø¹Ù† Ø§Ù„Ø¢Ø®Ø±Ø© Ù‡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>483911764674105344</td>\n",
       "      <td>http://t.co/4KAHaNd4an Ø³ÙŠØ¯ÙŠ Ø¥ÙŠÙÙ†ÙŠ : Ø´ÙƒØ§ÙŠØ© Ø£Ø¬Ù†Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>483798014239072256</td>\n",
       "      <td>Ø£Ø¹Ø¬Ø¨ØªÙ†ÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù€ #keek http://t.co/vORaVpTnJ9 Ø±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>483954767727980544</td>\n",
       "      <td>(Ø¥Ù†  Ø§Ù„Ø°ÙŠÙ†  ÙƒÙØ±ÙˆØ§  Ù…Ù†  Ø£Ù‡Ù„  Ø§Ù„ÙƒØªØ§Ø¨  ÙˆØ§Ù„Ù…Ø´Ø±ÙƒÙŠÙ† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>484025624076374016</td>\n",
       "      <td>Ø§Ù† ÙƒØ§Ù† ØºÙŠØ±ÙŠ Ø¹Ù† Ù‡ÙˆÙ‰ Ù‚Ù„Ø¨ÙŠ Ø§ØºÙ†Ø§ÙƒØŒ ÙŠØºÙ†ÙŠÙ†ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>483764454283558912</td>\n",
       "      <td>#Ø¨Ø­ØªØ±Ù…\\nØ§Ù„Ø´Ø®Øµ Ø§Ù„Ù„ÙŠ Ù…Ø§Ø´ÙŠ Ø¨Ù…Ø¨Ø¯Ø£ Ø§Ù„Ù„ÙŠ Ù…Ø±Ø¯Ù‡ÙˆØ´ Ø¹Ù„Ù‰ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>483918976129302528</td>\n",
       "      <td>@uu44pp @abunawafeid @3ajel_news Ø§Ù„ØµÙˆØ±Ù‡ Ù‡Ø§Ø°ÙŠ Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>483811483906625536</td>\n",
       "      <td>Ø­ØªÙ‰ Ø§Ù„Ù†Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹ØµÙŠÙ‡ ØªØ¤Ø¬Ø± Ø¹Ù„ÙŠÙ‡ - Ø³Ø¨Ø­Ø§Ù†Ùƒ ÙŠØ§Ù„Ù„Ù‡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>483782119827582977</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ù‚Ø¯Ø± Ù„Ù†Ø§ Ø§Ù„ÙØ±Ø­ Ø¨ÙƒÙ„ Ø§Ø´ÙƒØ§Ù„Ù‡ ØŒ Ø§Ù†Øª Ø§Ù„ÙƒØ±ÙŠÙ… Ø§Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>483780914452111360</td>\n",
       "      <td>{ÙˆØ£Ù†Ù‡ Ù‡Ùˆ Ø£ØºÙ†Ù‰ ÙˆØ£Ù‚Ù†Ù‰} [Ø§Ù„Ù†Ø¬Ù…:48]\\nhttp://t.co/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>483975567989956608</td>\n",
       "      <td>@AlwaaKsa ÙˆØ´ Ø­Ø·ÙŠØªÙŠ ØŸØŸ\\nØ§Ù†Ø§ Ø§Ù‚ÙˆÙ„ ØªÙŠÙØ§Ù†ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>483938071646584834</td>\n",
       "      <td>Ø­Ø³Ø¨ÙŠ Ø§Ù„Ù„Ù‡ Ù„Ø§ Ø¥Ù„Ù‡ Ø¥Ù„Ø§ Ù‡Ùˆ Ø¹Ù„ÙŠÙ‡ ØªÙˆÙƒÙ„Øª ÙˆÙ‡Ùˆ Ø±Ø¨ÙÙ‘ Ø§Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>483782693868433408</td>\n",
       "      <td>#ØºØ²Ù‡_ØªØ­Øª_Ø§Ù„Ù‚ØµÙ\\n\\nØ¯Ø§Ø¹Ø´ Ø£Ø®ÙˆØ§Ù†ÙŠ Ø­ÙŠÙ„ Ø¹Ù†Ø¯ÙƒÙ… Ø¨Ø§Ù„Ù…Ø¯Ù†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>484025449207451648</td>\n",
       "      <td>Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø­Ø§ÙÙ„Ø© ÙÙŠ â€œÙ‚Ù„ÙŠÙ‘Ø¨ Ø®Ø¶Ø±â€ Ø¨Ø§Ù„Ø¬ÙˆÙ Ø§Ù„Ù‰ Ø¥ØµØ§Ø¨Ø© 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>483942359281836032</td>\n",
       "      <td>@sarah66600  Ø§ÙŠ Ù…ÙˆÙ‚Ù ØªØªÙƒÙ„Ù…ÙŠÙ† Ø¹Ù†Ù‡ .. Ù‚ØµØ¯Ùƒ Ù…Ù„Ø§ÙŠÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>483770900127285248</td>\n",
       "      <td>Ø¨50 Ø±ÙŠØ§Ù„ Ø£ÙƒÙÙ„ Ù…Ø¹ØªÙ…Ø± ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ØŒ ÙˆÙ„Ùƒ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡ Ù…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>483866174556352512</td>\n",
       "      <td>@ana_bent_gad3a Ø§Ù„Ùˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>483770765985083392</td>\n",
       "      <td>ÙŠØ§ Ø§Ø¨Ùˆ Ø³Ù„Ùˆ Ø¹Ø±ÙØªÙ†ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66891</th>\n",
       "      <td>493381795287531520</td>\n",
       "      <td>é€™å€‹é€±æœ«å…©å¤©éƒ½è·Ÿ Navel å¾ˆæœ‰ç·£...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66892</th>\n",
       "      <td>493132254579675138</td>\n",
       "      <td>{CWB} æ¡ƒåœ’ç¸£ ä¸€é€±å¤©æ°£é å ±(07/27 05:00ç™¼å¸ƒ): 07/27 ç™½å¤© æº«åº¦:2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66893</th>\n",
       "      <td>488630113211518976</td>\n",
       "      <td>å…¶å¯¦æˆ‘å¾ˆæƒ³å•ï¼Œå™—æµªæ€éº¼é–å›æ‡‰ç„¶å¾Œåˆé–‹å•Ÿçš„#### http://t.co/sQBh6jmVoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66894</th>\n",
       "      <td>486899420798009344</td>\n",
       "      <td>-\\nè³€æ–‡p14\\nå°ç£è¨ªå•ä½ åœ°\\nå…¶ä»–æˆå“¡è©±ä½ ä¿‚å…¨éšŠæœ€å¤©ä¸æ€•åœ°ä¸æ€•æœé™£\\næˆ‘æ—ï¼š å¦‚æœä½ å»...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66895</th>\n",
       "      <td>492664113739231232</td>\n",
       "      <td>æˆ‘å·²æ”¶è· 817 é£Ÿç‰©ï¼http://t.co/JghsHr4QV4 #iphone, #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66896</th>\n",
       "      <td>487199504416768000</td>\n",
       "      <td>åŸºéš†å”¯ä¸€ä¸€å®¶ï¼ http://t.co/7f6yE7zKo2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66897</th>\n",
       "      <td>490456582136676352</td>\n",
       "      <td>æ³¨ä¸ªé”€éƒ½èƒ½æ­»æœºâ€¦â€¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66898</th>\n",
       "      <td>488488642370080769</td>\n",
       "      <td>å…¨å¹³å°ç¿»å¢™æŒ‡å—ï¼ˆPCï¼‹å®‰å“ï¼‹iOS+Mac+Linuxï¼‰[2014.7æ›´æ–°] https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66899</th>\n",
       "      <td>491992347278725120</td>\n",
       "      <td>ã€ ã€ å…è²»çš„å¥³æ€§å‘æˆ€æ„›éŠæˆ²â˜…æƒ³å’Œå“¥å“¥å‡çµå©šçœ‹çœ‹å—ï¼Ÿã€€https://t.co/YOUkKU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66900</th>\n",
       "      <td>491661312745676800</td>\n",
       "      <td>æˆ‘æ­£åœ¨ç©ã€Œç¥å¥³æ§ã€ï¼Œä¸€ä¸ªç»“åˆæ¼‚äº®å¡ç‰‡æˆ˜æ–—å’Œè¿·ä½ åŸå¸‚å»ºé€ çš„æ¸¸æˆï¼ä¸€èµ·å‚ä¸æˆ˜æ–—å»å†’é™©å§ï¼ htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66901</th>\n",
       "      <td>489025682597363714</td>\n",
       "      <td>ç°åœ¨çš„å¸¸è§„ä¸Šç­æ—¶é—´åŸºæœ¬ç¨³å®šåœ¨æ—©11æ™š9æˆ–10â€¦â€¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66902</th>\n",
       "      <td>494650331528433666</td>\n",
       "      <td>#204.7.25 èŠ±è“®å€æ¼æœƒ http://t.co/yOukLkXwCr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66903</th>\n",
       "      <td>494331450800361473</td>\n",
       "      <td>@shota_nuke å¥½åšï¼Œé‡ç‚¹æ˜¯æ£ç¢å’Œè’¸ï¼Œå«Œéº»çƒ¦å°±ä¸Šå‹åŠ›é”…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66904</th>\n",
       "      <td>485752157937741824</td>\n",
       "      <td>@makzihau å½“ç„¶æ˜¯å²åœ°å•¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66905</th>\n",
       "      <td>490766951061270528</td>\n",
       "      <td>è¯·åˆ«ä»¥ä¸ºä½ æœ‰å¤šéš¾å¿˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66906</th>\n",
       "      <td>484328282582577152</td>\n",
       "      <td>@EmmaKongms æ‰€ä»¥æˆ‘åœ°è¦å«æœ‹å‹ä¾†é–‹account å…ˆï¼Œç·Šæ€¥æƒ…æ³è¦è­˜è½‰å°ç‡Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66907</th>\n",
       "      <td>486841789866070016</td>\n",
       "      <td>@hundtw ä¸è¦çœ¯å•¦ ä¾†å–ä¸€æ¯å•¦ #å–‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66908</th>\n",
       "      <td>484996827121344512</td>\n",
       "      <td>ã€ŠéŸ³é€Ÿç¶“ç´€ã€‹æ–¼èƒŒåœ°è£¡æ”¯æ´éŸ³é€Ÿå­ å¼•å°ç©å®¶çš„ â€œéŸ³æ¨‚å¥³ç¥â€ã€Œç¹†æ–¯ã€ç™»å ´ http://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66909</th>\n",
       "      <td>491731230618963968</td>\n",
       "      <td>@immei0125 ç©ºè°ƒå‘¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66910</th>\n",
       "      <td>494627004973465601</td>\n",
       "      <td>Ace of Base - Unspeakable (Junk &amp;amp; Function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66911</th>\n",
       "      <td>493305178523963392</td>\n",
       "      <td>é‚£å°±ç‚¹64ä¸ªèµå“ˆ RT @ls691208:Â å¤§é…¥ä¸è¦å¥½äººå¡ï¼Œå¥½äººå¡æœ€åéƒ½æœ¨æœ‰å¥½ä¸‹åœºï¼RT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66912</th>\n",
       "      <td>484586108282736641</td>\n",
       "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66913</th>\n",
       "      <td>494052509619482625</td>\n",
       "      <td>å é¢†ç¾å¸  http://t.co/nBd1Rvy8WK http://t.co/Cy2UK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66914</th>\n",
       "      <td>485273015035244545</td>\n",
       "      <td>æˆ‘å–å¾—äº†ä¸€é¡¹æ–°æˆå°±ï¼š`ç®¡ç†å‘˜`.å°è¯•åœ¨iPadç‰ˆTribezæ¸¸æˆä¸­æ‰“è´¥æˆ‘å§ï¼http://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66915</th>\n",
       "      <td>484912347106926592</td>\n",
       "      <td>çƒ­ç‚¹æ–‡ç« ï¼šã€Šã€Šäº¬åŸ81å·ã€‹å´é•‡å®‡ç‰¹è¾‘â€”åœ¨çº¿æ’­æ”¾â€”ä¼˜é…·ç½‘ï¼Œè§†é¢‘é«˜æ¸…åœ¨çº¿è§‚çœ‹ã€‹ http://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66916</th>\n",
       "      <td>486035976079147009</td>\n",
       "      <td>å¤§ç«‹å…‰2450ç›¤ä¸­æ–°é«˜ å°è‚¡æ”¶æ¼²9520 http://t.co/T1x9EhD7mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66917</th>\n",
       "      <td>486299665873108992</td>\n",
       "      <td>çœŸä½›å®—å¤§é©¬å„åˆ†å ‚ä¸­å…ƒèŠ‚æ³•ä¼šæ´»åŠ¨ï¼Œæ¬¢è¿æŠ¤æŒ !\\n\\nå†œå†ä¸ƒæœˆçš„ã€ä¸­å…ƒç¯€ã€å³å°†åˆ°æ¥ã€‚å†œå†ä¸ƒæœˆæ˜¯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66918</th>\n",
       "      <td>490364709082652673</td>\n",
       "      <td>æˆ‘å·²æ”¶è· 2,211 é£Ÿç‰©ï¼http://t.co/Fo8dtabIw7 #android,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66919</th>\n",
       "      <td>484672019091300352</td>\n",
       "      <td>ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66920</th>\n",
       "      <td>491155187755515904</td>\n",
       "      <td>ä¸€åˆ†é˜ä¸–ç•Œç›ƒï¼http://t.co/yEvaMrp7ki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66921 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                                              Tweet\n",
       "0      483885347374243841  Ø§Ù„Ù„Ù‡Ù… Ø£ÙØ±Ø­ Ù‚Ù„Ø¨ÙŠ ÙˆÙ‚Ù„Ø¨ Ù…Ù† Ø£Ø­Ø¨ ÙˆØ£ØºØ³Ù„ Ø£Ø­Ø²Ø§Ù†Ù†Ø§ ÙˆÙ‡Ù…Ùˆ...\n",
       "1      484023414781263872  Ø¥Ø¶ØºØ· Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚ØªÙƒ ÙŠØªØ¨ÙŠÙ† Ù„Ùƒ ÙƒÙ… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª Ø¹Ù† ...\n",
       "2      484026168300273664  Ø§Ù„Ù„ÙÙ‘Ù‡ÙŒÙ…ÙÙ‘ ØµÙÙ„ÙÙ‘ ÙˆÙØ³ÙÙ„ÙÙ‘Ù…Ù’ Ø¹ÙÙ„Ù‰Ù° Ù†ÙØ¨ÙÙŠÙÙ‘Ù†ÙØ¢ Ù…Ù...\n",
       "3      483819942878650369  @Dinaa_ElAraby Ø§Ù‡Ø§ ÙŠØ§ Ø¨ÙŠØ¨ÙŠ ÙˆØ§Ù„Ù„Ù‡ Ø§ØªÙ‡Ø±Ø³Øª Ø¹Ù„ÙŠ ØªÙˆ...\n",
       "4      483793769079123971  â€¢ Ø§ÙØ¶Ù„ ÙƒØªØ§Ø¨ Ù‚Ø±Ø£ØªÙ‡ Ù‡Ùˆ : Ø£Ù…ÙŠ (Ø§Ø¨Ø±Ø§Ù‡Ø§Ù… Ù„Ù†ÙƒÙˆÙ„Ù†)\\nğŸŒ¹...\n",
       "5      483934868070350849              @hudc7721 Ø§Ù†ØªØ¸Ø±ÙŠ Ø§Ø¬Ù„ \\nØ®ÙŠØ±Ù‡ Ù„Ùƒ ÙŠØ§Ø±Ø¨ ğŸ˜˜\n",
       "6      483863369972473856  (ÙˆØ¥Ù† ØªØ¬Ù‡Ø± Ø¨Ø§Ù„Ù‚ÙˆÙ„ ÙØ¥Ù†Ù‡ ÙŠØ¹Ù„Ù… Ø§Ù„Ø³Ø± ÙˆØ£Ø®ÙÙ‰) [Ø·Ù‡:7]\\...\n",
       "7      483871567311413248  ïº§ï»ŸÙƒ ï»‹Ø²ï¯¾Ø² Ø¢ï»Ÿï»§ï»“Ø³ ï»ŸÛˆ ï®ªï»£Ûˆï»£Ùƒ ïºŸïº‘Ø¢Ù„Ù„Ø§ï­ ïº·ïº·ï®ÙŠ ï»Ÿï»Ÿï»§Ø¢ïº³Ø³ ï»£Ù† ...\n",
       "8      483931429902884864  Ø¹Ø´Ø§Ù† Ø§Ù„Ø¬Ù†Ù‘Ø© Ø£Ø¬Ù…Ù„ ØŸ  Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø¹Ø¯Ù†Ø§ Ø¹Ù† ÙƒÙ„ Ø°Ù†Ø¨ Ù…Ø§ÙŠØ®...\n",
       "9      483773756897124352  ØªÙˆØ¬ÙŠÙ‡ ÙƒÙŠÙÙŠØ© ØªØ«Ø¨ÙŠØª Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ø«Ø§Ø¨ØªØ© ROM Ø§Ù„ØªØ­Ù…ÙŠÙ„ ...\n",
       "10     483986544865210368                @dana_mahmod Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø­ÙƒÙŠÙƒ\n",
       "11     483873243598565376  @anabs_anabs @Rayedrd Ø£Ù†Ø´Ù‡Ø¯ Ø¨Ø³ ÙÙŠÙ‡ Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ø§Ø³ Ù„...\n",
       "12     483790646176935936  {ÙŠØ¹Ù„Ù…ÙˆÙ† Ø¸Ø§Ù‡Ø±Ø§ Ù…Ù† Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆÙ‡Ù… Ø¹Ù† Ø§Ù„Ø¢Ø®Ø±Ø© Ù‡...\n",
       "13     483911764674105344  http://t.co/4KAHaNd4an Ø³ÙŠØ¯ÙŠ Ø¥ÙŠÙÙ†ÙŠ : Ø´ÙƒØ§ÙŠØ© Ø£Ø¬Ù†Ø¨...\n",
       "14     483798014239072256  Ø£Ø¹Ø¬Ø¨ØªÙ†ÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù€ #keek http://t.co/vORaVpTnJ9 Ø±...\n",
       "15     483954767727980544  (Ø¥Ù†  Ø§Ù„Ø°ÙŠÙ†  ÙƒÙØ±ÙˆØ§  Ù…Ù†  Ø£Ù‡Ù„  Ø§Ù„ÙƒØªØ§Ø¨  ÙˆØ§Ù„Ù…Ø´Ø±ÙƒÙŠÙ† ...\n",
       "16     484025624076374016  Ø§Ù† ÙƒØ§Ù† ØºÙŠØ±ÙŠ Ø¹Ù† Ù‡ÙˆÙ‰ Ù‚Ù„Ø¨ÙŠ Ø§ØºÙ†Ø§ÙƒØŒ ÙŠØºÙ†ÙŠÙ†ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù† ...\n",
       "17     483764454283558912  #Ø¨Ø­ØªØ±Ù…\\nØ§Ù„Ø´Ø®Øµ Ø§Ù„Ù„ÙŠ Ù…Ø§Ø´ÙŠ Ø¨Ù…Ø¨Ø¯Ø£ Ø§Ù„Ù„ÙŠ Ù…Ø±Ø¯Ù‡ÙˆØ´ Ø¹Ù„Ù‰ ...\n",
       "18     483918976129302528  @uu44pp @abunawafeid @3ajel_news Ø§Ù„ØµÙˆØ±Ù‡ Ù‡Ø§Ø°ÙŠ Ø§...\n",
       "19     483811483906625536  Ø­ØªÙ‰ Ø§Ù„Ù†Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹ØµÙŠÙ‡ ØªØ¤Ø¬Ø± Ø¹Ù„ÙŠÙ‡ - Ø³Ø¨Ø­Ø§Ù†Ùƒ ÙŠØ§Ù„Ù„Ù‡...\n",
       "20     483782119827582977  Ø§Ù„Ù„Ù‡Ù… Ù‚Ø¯Ø± Ù„Ù†Ø§ Ø§Ù„ÙØ±Ø­ Ø¨ÙƒÙ„ Ø§Ø´ÙƒØ§Ù„Ù‡ ØŒ Ø§Ù†Øª Ø§Ù„ÙƒØ±ÙŠÙ… Ø§Ù„...\n",
       "21     483780914452111360  {ÙˆØ£Ù†Ù‡ Ù‡Ùˆ Ø£ØºÙ†Ù‰ ÙˆØ£Ù‚Ù†Ù‰} [Ø§Ù„Ù†Ø¬Ù…:48]\\nhttp://t.co/i...\n",
       "22     483975567989956608             @AlwaaKsa ÙˆØ´ Ø­Ø·ÙŠØªÙŠ ØŸØŸ\\nØ§Ù†Ø§ Ø§Ù‚ÙˆÙ„ ØªÙŠÙØ§Ù†ÙŠ\n",
       "23     483938071646584834  Ø­Ø³Ø¨ÙŠ Ø§Ù„Ù„Ù‡ Ù„Ø§ Ø¥Ù„Ù‡ Ø¥Ù„Ø§ Ù‡Ùˆ Ø¹Ù„ÙŠÙ‡ ØªÙˆÙƒÙ„Øª ÙˆÙ‡Ùˆ Ø±Ø¨ÙÙ‘ Ø§Ù„...\n",
       "24     483782693868433408  #ØºØ²Ù‡_ØªØ­Øª_Ø§Ù„Ù‚ØµÙ\\n\\nØ¯Ø§Ø¹Ø´ Ø£Ø®ÙˆØ§Ù†ÙŠ Ø­ÙŠÙ„ Ø¹Ù†Ø¯ÙƒÙ… Ø¨Ø§Ù„Ù…Ø¯Ù†...\n",
       "25     484025449207451648  Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø­Ø§ÙÙ„Ø© ÙÙŠ â€œÙ‚Ù„ÙŠÙ‘Ø¨ Ø®Ø¶Ø±â€ Ø¨Ø§Ù„Ø¬ÙˆÙ Ø§Ù„Ù‰ Ø¥ØµØ§Ø¨Ø© 7...\n",
       "26     483942359281836032  @sarah66600  Ø§ÙŠ Ù…ÙˆÙ‚Ù ØªØªÙƒÙ„Ù…ÙŠÙ† Ø¹Ù†Ù‡ .. Ù‚ØµØ¯Ùƒ Ù…Ù„Ø§ÙŠÙŠ...\n",
       "27     483770900127285248  Ø¨50 Ø±ÙŠØ§Ù„ Ø£ÙƒÙÙ„ Ù…Ø¹ØªÙ…Ø± ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ØŒ ÙˆÙ„Ùƒ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡ Ù…...\n",
       "28     483866174556352512                                @ana_bent_gad3a Ø§Ù„Ùˆ\n",
       "29     483770765985083392                                  ÙŠØ§ Ø§Ø¨Ùˆ Ø³Ù„Ùˆ Ø¹Ø±ÙØªÙ†ÙŠ\n",
       "...                   ...                                                ...\n",
       "66891  493381795287531520                              é€™å€‹é€±æœ«å…©å¤©éƒ½è·Ÿ Navel å¾ˆæœ‰ç·£...\n",
       "66892  493132254579675138  {CWB} æ¡ƒåœ’ç¸£ ä¸€é€±å¤©æ°£é å ±(07/27 05:00ç™¼å¸ƒ): 07/27 ç™½å¤© æº«åº¦:2...\n",
       "66893  488630113211518976    å…¶å¯¦æˆ‘å¾ˆæƒ³å•ï¼Œå™—æµªæ€éº¼é–å›æ‡‰ç„¶å¾Œåˆé–‹å•Ÿçš„#### http://t.co/sQBh6jmVoW\n",
       "66894  486899420798009344  -\\nè³€æ–‡p14\\nå°ç£è¨ªå•ä½ åœ°\\nå…¶ä»–æˆå“¡è©±ä½ ä¿‚å…¨éšŠæœ€å¤©ä¸æ€•åœ°ä¸æ€•æœé™£\\næˆ‘æ—ï¼š å¦‚æœä½ å»...\n",
       "66895  492664113739231232  æˆ‘å·²æ”¶è· 817 é£Ÿç‰©ï¼http://t.co/JghsHr4QV4 #iphone, #i...\n",
       "66896  487199504416768000                     åŸºéš†å”¯ä¸€ä¸€å®¶ï¼ http://t.co/7f6yE7zKo2\n",
       "66897  490456582136676352                                          æ³¨ä¸ªé”€éƒ½èƒ½æ­»æœºâ€¦â€¦\n",
       "66898  488488642370080769  å…¨å¹³å°ç¿»å¢™æŒ‡å—ï¼ˆPCï¼‹å®‰å“ï¼‹iOS+Mac+Linuxï¼‰[2014.7æ›´æ–°] https:/...\n",
       "66899  491992347278725120  ã€ ã€ å…è²»çš„å¥³æ€§å‘æˆ€æ„›éŠæˆ²â˜…æƒ³å’Œå“¥å“¥å‡çµå©šçœ‹çœ‹å—ï¼Ÿã€€https://t.co/YOUkKU...\n",
       "66900  491661312745676800  æˆ‘æ­£åœ¨ç©ã€Œç¥å¥³æ§ã€ï¼Œä¸€ä¸ªç»“åˆæ¼‚äº®å¡ç‰‡æˆ˜æ–—å’Œè¿·ä½ åŸå¸‚å»ºé€ çš„æ¸¸æˆï¼ä¸€èµ·å‚ä¸æˆ˜æ–—å»å†’é™©å§ï¼ htt...\n",
       "66901  489025682597363714                           ç°åœ¨çš„å¸¸è§„ä¸Šç­æ—¶é—´åŸºæœ¬ç¨³å®šåœ¨æ—©11æ™š9æˆ–10â€¦â€¦\n",
       "66902  494650331528433666             #204.7.25 èŠ±è“®å€æ¼æœƒ http://t.co/yOukLkXwCr\n",
       "66903  494331450800361473                    @shota_nuke å¥½åšï¼Œé‡ç‚¹æ˜¯æ£ç¢å’Œè’¸ï¼Œå«Œéº»çƒ¦å°±ä¸Šå‹åŠ›é”…\n",
       "66904  485752157937741824                                   @makzihau å½“ç„¶æ˜¯å²åœ°å•¦\n",
       "66905  490766951061270528                                          è¯·åˆ«ä»¥ä¸ºä½ æœ‰å¤šéš¾å¿˜\n",
       "66906  484328282582577152   @EmmaKongms æ‰€ä»¥æˆ‘åœ°è¦å«æœ‹å‹ä¾†é–‹account å…ˆï¼Œç·Šæ€¥æƒ…æ³è¦è­˜è½‰å°ç‡Twitter\n",
       "66907  486841789866070016                              @hundtw ä¸è¦çœ¯å•¦ ä¾†å–ä¸€æ¯å•¦ #å–‚\n",
       "66908  484996827121344512  ã€ŠéŸ³é€Ÿç¶“ç´€ã€‹æ–¼èƒŒåœ°è£¡æ”¯æ´éŸ³é€Ÿå­ å¼•å°ç©å®¶çš„ â€œéŸ³æ¨‚å¥³ç¥â€ã€Œç¹†æ–¯ã€ç™»å ´ http://t.co...\n",
       "66909  491731230618963968                                     @immei0125 ç©ºè°ƒå‘¢\n",
       "66910  494627004973465601  Ace of Base - Unspeakable (Junk &amp; Function...\n",
       "66911  493305178523963392  é‚£å°±ç‚¹64ä¸ªèµå“ˆ RT @ls691208:Â å¤§é…¥ä¸è¦å¥½äººå¡ï¼Œå¥½äººå¡æœ€åéƒ½æœ¨æœ‰å¥½ä¸‹åœºï¼RT ...\n",
       "66912  484586108282736641                  @Official_SABC1 Moloooo nakuwe!!!\n",
       "66913  494052509619482625  å é¢†ç¾å¸  http://t.co/nBd1Rvy8WK http://t.co/Cy2UK...\n",
       "66914  485273015035244545  æˆ‘å–å¾—äº†ä¸€é¡¹æ–°æˆå°±ï¼š`ç®¡ç†å‘˜`.å°è¯•åœ¨iPadç‰ˆTribezæ¸¸æˆä¸­æ‰“è´¥æˆ‘å§ï¼http://t...\n",
       "66915  484912347106926592  çƒ­ç‚¹æ–‡ç« ï¼šã€Šã€Šäº¬åŸ81å·ã€‹å´é•‡å®‡ç‰¹è¾‘â€”åœ¨çº¿æ’­æ”¾â€”ä¼˜é…·ç½‘ï¼Œè§†é¢‘é«˜æ¸…åœ¨çº¿è§‚çœ‹ã€‹ http://t...\n",
       "66916  486035976079147009        å¤§ç«‹å…‰2450ç›¤ä¸­æ–°é«˜ å°è‚¡æ”¶æ¼²9520 http://t.co/T1x9EhD7mi\n",
       "66917  486299665873108992  çœŸä½›å®—å¤§é©¬å„åˆ†å ‚ä¸­å…ƒèŠ‚æ³•ä¼šæ´»åŠ¨ï¼Œæ¬¢è¿æŠ¤æŒ !\\n\\nå†œå†ä¸ƒæœˆçš„ã€ä¸­å…ƒç¯€ã€å³å°†åˆ°æ¥ã€‚å†œå†ä¸ƒæœˆæ˜¯...\n",
       "66918  490364709082652673  æˆ‘å·²æ”¶è· 2,211 é£Ÿç‰©ï¼http://t.co/Fo8dtabIw7 #android,...\n",
       "66919  484672019091300352  ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥...\n",
       "66920  491155187755515904                      ä¸€åˆ†é˜ä¸–ç•Œç›ƒï¼http://t.co/yEvaMrp7ki\n",
       "\n",
       "[66921 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets # looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with both label documents\n",
    "\n",
    "train_dev_labels = pd.read_csv(TRAIN_DEV_FP, sep='\\t', header=None, names=[COL_LABEL, COL_ID])\n",
    "test_labels = pd.read_csv(TEST_FP, sep='\\t', header=None, names=[COL_LABEL, COL_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ar</td>\n",
       "      <td>483762194908479488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ar</td>\n",
       "      <td>483762916097654784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ar</td>\n",
       "      <td>483764828784582656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ar</td>\n",
       "      <td>483765526683209728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ar</td>\n",
       "      <td>483768342315282432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ar</td>\n",
       "      <td>483770765985083392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ar</td>\n",
       "      <td>483770900127285248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ar</td>\n",
       "      <td>483770997892345857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ar</td>\n",
       "      <td>483773690769702912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ar</td>\n",
       "      <td>483773756897124352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ar</td>\n",
       "      <td>483777578163908609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ar</td>\n",
       "      <td>483780914452111360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ar</td>\n",
       "      <td>483782119827582977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ar</td>\n",
       "      <td>483782693868433408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ar</td>\n",
       "      <td>483783499174772736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ar</td>\n",
       "      <td>483783505445265409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ar</td>\n",
       "      <td>483790646176935936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ar</td>\n",
       "      <td>483793769079123971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ar</td>\n",
       "      <td>483796613656109056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ar</td>\n",
       "      <td>483796979063848960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ar</td>\n",
       "      <td>483799673044344832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ar</td>\n",
       "      <td>483802793459736576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ar</td>\n",
       "      <td>483805955852107776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ar</td>\n",
       "      <td>483807295134900224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ar</td>\n",
       "      <td>483811483906625536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ar</td>\n",
       "      <td>483818326599426048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ar</td>\n",
       "      <td>483819942878650369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ar</td>\n",
       "      <td>483824293952749568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ar</td>\n",
       "      <td>483831683653697537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ar</td>\n",
       "      <td>483848516356562945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96384</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>492581164196978690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96385</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>492602588031090689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96386</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>492664113739231232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96387</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493280795314753536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96388</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493305178523963392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96389</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493466690378686466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96390</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493645244248756224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96391</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494052509619482625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96392</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494068544120705025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96393</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494331450800361473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96394</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494627004973465601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96395</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494730046020403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96396</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>483849852225196032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96397</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>484245222742704128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96398</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>484328282582577152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96399</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>484996827121344512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96400</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>486035976079147009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96401</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>486841789866070016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96402</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>486899420798009344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96403</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>488630113211518976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96404</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>489697736854634496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96405</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>490149224416174081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96406</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>490514766029279233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96407</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>490667138081099776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96408</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>491155187755515904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96409</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>492349820346974209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96410</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>493132254579675138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96411</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>493381795287531520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96412</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>493643635632930816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96413</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>494059705564553216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96414 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                  ID\n",
       "0        ar   483762194908479488\n",
       "1         ar  483762916097654784\n",
       "2         ar  483764828784582656\n",
       "3         ar  483765526683209728\n",
       "4         ar  483768342315282432\n",
       "5         ar  483770765985083392\n",
       "6         ar  483770900127285248\n",
       "7         ar  483770997892345857\n",
       "8         ar  483773690769702912\n",
       "9         ar  483773756897124352\n",
       "10        ar  483777578163908609\n",
       "11        ar  483780914452111360\n",
       "12        ar  483782119827582977\n",
       "13        ar  483782693868433408\n",
       "14        ar  483783499174772736\n",
       "15        ar  483783505445265409\n",
       "16        ar  483790646176935936\n",
       "17        ar  483793769079123971\n",
       "18        ar  483796613656109056\n",
       "19        ar  483796979063848960\n",
       "20        ar  483799673044344832\n",
       "21        ar  483802793459736576\n",
       "22        ar  483805955852107776\n",
       "23        ar  483807295134900224\n",
       "24        ar  483811483906625536\n",
       "25        ar  483818326599426048\n",
       "26        ar  483819942878650369\n",
       "27        ar  483824293952749568\n",
       "28        ar  483831683653697537\n",
       "29        ar  483848516356562945\n",
       "...      ...                 ...\n",
       "96384  zh-CN  492581164196978690\n",
       "96385  zh-CN  492602588031090689\n",
       "96386  zh-CN  492664113739231232\n",
       "96387  zh-CN  493280795314753536\n",
       "96388  zh-CN  493305178523963392\n",
       "96389  zh-CN  493466690378686466\n",
       "96390  zh-CN  493645244248756224\n",
       "96391  zh-CN  494052509619482625\n",
       "96392  zh-CN  494068544120705025\n",
       "96393  zh-CN  494331450800361473\n",
       "96394  zh-CN  494627004973465601\n",
       "96395  zh-CN  494730046020403200\n",
       "96396  zh-TW  483849852225196032\n",
       "96397  zh-TW  484245222742704128\n",
       "96398  zh-TW  484328282582577152\n",
       "96399  zh-TW  484996827121344512\n",
       "96400  zh-TW  486035976079147009\n",
       "96401  zh-TW  486841789866070016\n",
       "96402  zh-TW  486899420798009344\n",
       "96403  zh-TW  488630113211518976\n",
       "96404  zh-TW  489697736854634496\n",
       "96405  zh-TW  490149224416174081\n",
       "96406  zh-TW  490514766029279233\n",
       "96407  zh-TW  490667138081099776\n",
       "96408  zh-TW  491155187755515904\n",
       "96409  zh-TW  492349820346974209\n",
       "96410  zh-TW  493132254579675138\n",
       "96411  zh-TW  493381795287531520\n",
       "96412  zh-TW  493643635632930816\n",
       "96413  zh-TW  494059705564553216\n",
       "\n",
       "[96414 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_labels # looks about right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[COL_ID]=tweets[COL_ID].astype(int) # to allow for merge, need the same type\n",
    "\n",
    "train_dev_data = pd.merge(tweets, train_dev_labels, on=COL_ID) # merge by ID\n",
    "test_data = pd.merge(tweets, test_labels, on=COL_ID) # merge by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483885347374243841</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø£ÙØ±Ø­ Ù‚Ù„Ø¨ÙŠ ÙˆÙ‚Ù„Ø¨ Ù…Ù† Ø£Ø­Ø¨ ÙˆØ£ØºØ³Ù„ Ø£Ø­Ø²Ø§Ù†Ù†Ø§ ÙˆÙ‡Ù…Ùˆ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484023414781263872</td>\n",
       "      <td>Ø¥Ø¶ØºØ· Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚ØªÙƒ ÙŠØªØ¨ÙŠÙ† Ù„Ùƒ ÙƒÙ… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª Ø¹Ù† ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484026168300273664</td>\n",
       "      <td>Ø§Ù„Ù„ÙÙ‘Ù‡ÙŒÙ…ÙÙ‘ ØµÙÙ„ÙÙ‘ ÙˆÙØ³ÙÙ„ÙÙ‘Ù…Ù’ Ø¹ÙÙ„Ù‰Ù° Ù†ÙØ¨ÙÙŠÙÙ‘Ù†ÙØ¢ Ù…Ù...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483819942878650369</td>\n",
       "      <td>@Dinaa_ElAraby Ø§Ù‡Ø§ ÙŠØ§ Ø¨ÙŠØ¨ÙŠ ÙˆØ§Ù„Ù„Ù‡ Ø§ØªÙ‡Ø±Ø³Øª Ø¹Ù„ÙŠ ØªÙˆ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>483793769079123971</td>\n",
       "      <td>â€¢ Ø§ÙØ¶Ù„ ÙƒØªØ§Ø¨ Ù‚Ø±Ø£ØªÙ‡ Ù‡Ùˆ : Ø£Ù…ÙŠ (Ø§Ø¨Ø±Ø§Ù‡Ø§Ù… Ù„Ù†ÙƒÙˆÙ„Ù†)\\nğŸŒ¹...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                              Tweet Label\n",
       "0  483885347374243841  Ø§Ù„Ù„Ù‡Ù… Ø£ÙØ±Ø­ Ù‚Ù„Ø¨ÙŠ ÙˆÙ‚Ù„Ø¨ Ù…Ù† Ø£Ø­Ø¨ ÙˆØ£ØºØ³Ù„ Ø£Ø­Ø²Ø§Ù†Ù†Ø§ ÙˆÙ‡Ù…Ùˆ...    ar\n",
       "1  484023414781263872  Ø¥Ø¶ØºØ· Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚ØªÙƒ ÙŠØªØ¨ÙŠÙ† Ù„Ùƒ ÙƒÙ… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª Ø¹Ù† ...    ar\n",
       "2  484026168300273664  Ø§Ù„Ù„ÙÙ‘Ù‡ÙŒÙ…ÙÙ‘ ØµÙÙ„ÙÙ‘ ÙˆÙØ³ÙÙ„ÙÙ‘Ù…Ù’ Ø¹ÙÙ„Ù‰Ù° Ù†ÙØ¨ÙÙŠÙÙ‘Ù†ÙØ¢ Ù…Ù...    ar\n",
       "3  483819942878650369  @Dinaa_ElAraby Ø§Ù‡Ø§ ÙŠØ§ Ø¨ÙŠØ¨ÙŠ ÙˆØ§Ù„Ù„Ù‡ Ø§ØªÙ‡Ø±Ø³Øª Ø¹Ù„ÙŠ ØªÙˆ...    ar\n",
       "4  483793769079123971  â€¢ Ø§ÙØ¶Ù„ ÙƒØªØ§Ø¨ Ù‚Ø±Ø£ØªÙ‡ Ù‡Ùˆ : Ø£Ù…ÙŠ (Ø§Ø¨Ø±Ø§Ù‡Ø§Ù… Ù„Ù†ÙƒÙˆÙ„Ù†)\\nğŸŒ¹...    ar"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13447</th>\n",
       "      <td>491992347278725120</td>\n",
       "      <td>ã€ ã€ å…è²»çš„å¥³æ€§å‘æˆ€æ„›éŠæˆ²â˜…æƒ³å’Œå“¥å“¥å‡çµå©šçœ‹çœ‹å—ï¼Ÿã€€https://t.co/YOUkKU...</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13448</th>\n",
       "      <td>494650331528433666</td>\n",
       "      <td>#204.7.25 èŠ±è“®å€æ¼æœƒ http://t.co/yOukLkXwCr</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13449</th>\n",
       "      <td>485752157937741824</td>\n",
       "      <td>@makzihau å½“ç„¶æ˜¯å²åœ°å•¦</td>\n",
       "      <td>zh-CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13450</th>\n",
       "      <td>484586108282736641</td>\n",
       "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
       "      <td>zu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13451</th>\n",
       "      <td>484672019091300352</td>\n",
       "      <td>ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥...</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                                              Tweet  \\\n",
       "13447  491992347278725120  ã€ ã€ å…è²»çš„å¥³æ€§å‘æˆ€æ„›éŠæˆ²â˜…æƒ³å’Œå“¥å“¥å‡çµå©šçœ‹çœ‹å—ï¼Ÿã€€https://t.co/YOUkKU...   \n",
       "13448  494650331528433666             #204.7.25 èŠ±è“®å€æ¼æœƒ http://t.co/yOukLkXwCr   \n",
       "13449  485752157937741824                                   @makzihau å½“ç„¶æ˜¯å²åœ°å•¦   \n",
       "13450  484586108282736641                  @Official_SABC1 Moloooo nakuwe!!!   \n",
       "13451  484672019091300352  ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥çµ±ä¸€ç²¾ç¥...   \n",
       "\n",
       "       Label  \n",
       "13447  zh-TW  \n",
       "13448  zh-TW  \n",
       "13449  zh-CN  \n",
       "13450     zu  \n",
       "13451  zh-TW  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_n_shuffle(data):\n",
    "    data_no_na = data.dropna().copy()\n",
    "    return data_no_na.sample(frac=1)\n",
    "\n",
    "train_dev_set = drop_n_shuffle(train_dev_data).reset_index(drop = True)\n",
    "test_set = drop_n_shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ID                                              Tweet Label\n",
      "0  490917308399763457   \"Hold on I'm going to brush a horse.\" -Willow ğŸ˜‚ğŸ˜‚    en\n",
      "1  493347986013822976  @atsushi022518 \\nã‚ã£ã¡ã‚ƒã‚“ã€ã¦ã‚“ã­ã‚“ã˜ã‚ƒãªã„ã‚ˆã€‚å¤©æ‰ã ã‚ˆğŸ’«ãŠã•ã¨ã†ã¯ã¾ã¡ãŒ...    ja\n",
      "2  484938267268091904         Ğ£Ğ¿Ñ€ÑƒĞ³Ğ¾Ğµ Ñ‚ĞµĞ»Ğ¾â€¦ (18+) http://t.co/xpXN8rDqED    ru\n",
      "3  490853889978007552                               @chiyari_ Thanks !!!    en\n",
      "4  490161646678327296                                 ×™×©×¨××œ ×”×™× ×”×‘×™×ª ×©×œ×™    he\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                       ID                                              Tweet  \\\n",
      "11820  484392947555643392  @mk62442 @P0406L à¹€à¸”à¸µà¹‹à¸¢à¸§à¹ƒà¸«à¹‰à¹‚à¸§à¸¥à¹€à¸”à¸­à¸£à¹Œà¸¡à¸­à¸•à¹Œà¸à¸²à¸•à¸±à¸§à¸¡à¸² ^.^   \n",
      "11022  486685688243699713                               Segunda tem aula -.-   \n",
      "11843  487509040751054850                       à¸¥à¸´à¸¡à¸´à¸•à¸«à¸£à¸­ à¸à¸µà¹‰ #SbsPopAsiaGOT7   \n",
      "11142  488795219643858945        chego quem desconcentra o duca #ODucaChegou   \n",
      "3044   489696421713833984  @Ferenc2017 Grrrrrrr!!!!! They have some splai...   \n",
      "\n",
      "      Label  \n",
      "11820    th  \n",
      "11022    pt  \n",
      "11843    th  \n",
      "11142    pt  \n",
      "3044     en  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(train_dev_set.head()) #some checks\n",
    "print(type(train_dev_set))\n",
    "print(test_set.head())\n",
    "print(type(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the ID columns, not needed anymore\n",
    "\n",
    "train_dev = train_dev_set.drop(COL_ID, axis=1)\n",
    "test = test_set.drop(COL_ID, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hold on I'm going to brush a horse.\" -Willow ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@atsushi022518 \\nã‚ã£ã¡ã‚ƒã‚“ã€ã¦ã‚“ã­ã‚“ã˜ã‚ƒãªã„ã‚ˆã€‚å¤©æ‰ã ã‚ˆğŸ’«ãŠã•ã¨ã†ã¯ã¾ã¡ãŒ...</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ğ£Ğ¿Ñ€ÑƒĞ³Ğ¾Ğµ Ñ‚ĞµĞ»Ğ¾â€¦ (18+) http://t.co/xpXN8rDqED</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chiyari_ Thanks !!!</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>×™×©×¨××œ ×”×™× ×”×‘×™×ª ×©×œ×™</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Label\n",
       "0   \"Hold on I'm going to brush a horse.\" -Willow ğŸ˜‚ğŸ˜‚    en\n",
       "1  @atsushi022518 \\nã‚ã£ã¡ã‚ƒã‚“ã€ã¦ã‚“ã­ã‚“ã˜ã‚ƒãªã„ã‚ˆã€‚å¤©æ‰ã ã‚ˆğŸ’«ãŠã•ã¨ã†ã¯ã¾ã¡ãŒ...    ja\n",
       "2         Ğ£Ğ¿Ñ€ÑƒĞ³Ğ¾Ğµ Ñ‚ĞµĞ»Ğ¾â€¦ (18+) http://t.co/xpXN8rDqED    ru\n",
       "3                               @chiyari_ Thanks !!!    en\n",
       "4                                 ×™×©×¨××œ ×”×™× ×”×‘×™×ª ×©×œ×™    he"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>@mk62442 @P0406L à¹€à¸”à¸µà¹‹à¸¢à¸§à¹ƒà¸«à¹‰à¹‚à¸§à¸¥à¹€à¸”à¸­à¸£à¹Œà¸¡à¸­à¸•à¹Œà¸à¸²à¸•à¸±à¸§à¸¡à¸² ^.^</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11022</th>\n",
       "      <td>Segunda tem aula -.-</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11843</th>\n",
       "      <td>à¸¥à¸´à¸¡à¸´à¸•à¸«à¸£à¸­ à¸à¸µà¹‰ #SbsPopAsiaGOT7</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11142</th>\n",
       "      <td>chego quem desconcentra o duca #ODucaChegou</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>@Ferenc2017 Grrrrrrr!!!!! They have some splai...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet Label\n",
       "11820  @mk62442 @P0406L à¹€à¸”à¸µà¹‹à¸¢à¸§à¹ƒà¸«à¹‰à¹‚à¸§à¸¥à¹€à¸”à¸­à¸£à¹Œà¸¡à¸­à¸•à¹Œà¸à¸²à¸•à¸±à¸§à¸¡à¸² ^.^    th\n",
       "11022                               Segunda tem aula -.-    pt\n",
       "11843                       à¸¥à¸´à¸¡à¸´à¸•à¸«à¸£à¸­ à¸à¸µà¹‰ #SbsPopAsiaGOT7    th\n",
       "11142        chego quem desconcentra o duca #ODucaChegou    pt\n",
       "3044   @Ferenc2017 Grrrrrrr!!!!! They have some splai...    en"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53469</td>\n",
       "      <td>53469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>53385</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>:(</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8</td>\n",
       "      <td>18764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tweet  Label\n",
       "count   53469  53469\n",
       "unique  53385     77\n",
       "top        :(     en\n",
       "freq        8  18764"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.describe() # descrption of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ar          2295\n",
       "ar             1\n",
       "ar_LATN       12\n",
       "az             1\n",
       "bg             2\n",
       "bn             8\n",
       "bs             4\n",
       "ca            22\n",
       "cs             4\n",
       "cy             1\n",
       "da             7\n",
       "de           171\n",
       "dv             1\n",
       "el            39\n",
       "en         18764\n",
       "es          5978\n",
       "et             2\n",
       "fa            18\n",
       "fi            15\n",
       "fr           954\n",
       "gl             3\n",
       "ha             1\n",
       "he            27\n",
       "hi            16\n",
       "hi-Latn       15\n",
       "hr             5\n",
       "ht             2\n",
       "hu            15\n",
       "hy             2\n",
       "id          3038\n",
       "           ...  \n",
       "nl           182\n",
       "no            11\n",
       "pl            93\n",
       "ps             1\n",
       "ps_LATN        1\n",
       "pt          2888\n",
       "ro            12\n",
       "ru           978\n",
       "si             1\n",
       "sl             2\n",
       "sq             9\n",
       "sr            22\n",
       "su            10\n",
       "sv            54\n",
       "sw             6\n",
       "ta             9\n",
       "ta_LATN        1\n",
       "th           465\n",
       "tl           320\n",
       "tn             1\n",
       "tr           669\n",
       "uk            16\n",
       "und         4835\n",
       "ur             7\n",
       "ur_LATN       12\n",
       "vi            16\n",
       "wo             1\n",
       "xh             1\n",
       "zh-CN         25\n",
       "zh-TW         10\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.groupby(COL_LABEL).size() # more description of the data. See that there are lots of Arabian and English tweets, also quite a few in Spanish and Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dev.Tweet # split the data in Series\n",
    "y_train = train_dev.Label\n",
    "X_test = test.Tweet\n",
    "y_test = test.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#encode the labels. First step means simple encoding, the second makes a series out of the array that was outputted and\n",
    "    #the third step means we output strings again (strings are apparently needed as a format)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_train_series = pd.Series(y_train_encoded)\n",
    "y_train_str = y_train_series.apply(str)\n",
    "\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "y_test_series = pd.Series(y_test_encoded)\n",
    "y_test_str = y_test_series.apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Language classification with linear classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline1 = Pipeline([('tfidf', TfidfVectorizer()), ('clf0', MultinomialNB())]) #first test with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...ue,\n",
       "        vocabulary=None)), ('clf0', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline1.fit(X_train, y_train_str) #using y_train_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['28', '28', '31', ..., '13', '13', '13'], dtype='<U2')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        21\n",
       "1        21\n",
       "2        23\n",
       "3        10\n",
       "4        21\n",
       "5        23\n",
       "6        10\n",
       "7        34\n",
       "8        10\n",
       "9        21\n",
       "10       11\n",
       "11       11\n",
       "12        0\n",
       "13        0\n",
       "14       50\n",
       "15        0\n",
       "16       10\n",
       "17       23\n",
       "18       23\n",
       "19       10\n",
       "20       23\n",
       "21       10\n",
       "22       10\n",
       "23       10\n",
       "24       10\n",
       "25       23\n",
       "26       11\n",
       "27       50\n",
       "28       11\n",
       "29       10\n",
       "         ..\n",
       "13422    23\n",
       "13423    10\n",
       "13424    10\n",
       "13425     0\n",
       "13426    41\n",
       "13427    10\n",
       "13428     0\n",
       "13429    39\n",
       "13430    10\n",
       "13431    23\n",
       "13432    23\n",
       "13433    10\n",
       "13434    23\n",
       "13435    10\n",
       "13436    10\n",
       "13437    10\n",
       "13438    52\n",
       "13439    10\n",
       "13440    10\n",
       "13441    23\n",
       "13442    10\n",
       "13443    10\n",
       "13444    10\n",
       "13445    10\n",
       "13446    41\n",
       "13447    10\n",
       "13448    11\n",
       "13449     0\n",
       "13450     3\n",
       "13451    23\n",
       "Length: 13452, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test_str #doesn't look too right, but it is a very simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first serious pipeline with ngrams and tfidf --> just for test!\n",
    "pipeline_NB01 = Pipeline([\n",
    "    ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf01', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid is fitting the pipeline_NB01\n",
    "param_grid01 = {'clf01__alpha': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'clf01__fit_prior': [True, False]}  #'ngram__ngram_range': [(1, 1), (1, 2), (1, 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  16 out of  16 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('ngram', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
       "        stri...ear_tf=False, use_idf=True)), ('clf01', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'clf01__alpha': [0.2, 0.6, 0.8, 1.0], 'clf01__fit_prior': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This model here seems to work\n",
    "gs_NB01= GridSearchCV(pipeline_NB01, param_grid01, cv=2, n_jobs=2, verbose=1)\n",
    "gs_NB01.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['th', 'pt', 'th', ..., 'pt', 'es', 'tl'], dtype='<U7')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_NB01 = gs_NB01.predict(X_test)\n",
    "y_NB01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11820         th\n",
       "11022         pt\n",
       "11843         th\n",
       "11142         pt\n",
       "3044          en\n",
       "3753          en\n",
       "12143         tr\n",
       "9873          ja\n",
       "7079          fr\n",
       "3522          en\n",
       "2427          en\n",
       "8955          ja\n",
       "11056         pt\n",
       "2266          en\n",
       "10209         ja\n",
       "6013          es\n",
       "2235          en\n",
       "4007          en\n",
       "7556          id\n",
       "4080          en\n",
       "10281         ja\n",
       "9641          ja\n",
       "547      ar_LATN\n",
       "9551          ja\n",
       "5369          en\n",
       "10189         ja\n",
       "550           bg\n",
       "7831          id\n",
       "1347          en\n",
       "10686         ko\n",
       "          ...   \n",
       "8269          ja\n",
       "11124         pt\n",
       "5627          es\n",
       "1532          en\n",
       "2264          en\n",
       "7119          fr\n",
       "6286          es\n",
       "1817          en\n",
       "1497          en\n",
       "2817          en\n",
       "10927         pt\n",
       "6646          es\n",
       "9908          ja\n",
       "4252          en\n",
       "8662          ja\n",
       "9708          ja\n",
       "2150          en\n",
       "6090          es\n",
       "7868          id\n",
       "11810         sv\n",
       "9268          ja\n",
       "9170          ja\n",
       "11331         pt\n",
       "6446          es\n",
       "1287          en\n",
       "2569          en\n",
       "7286          id\n",
       "13226        und\n",
       "6049          es\n",
       "12008         tl\n",
       "Name: Label, Length: 13452, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test #results are quite terrible though \n",
    "# they are actually better than with the avg word length extractor included in the features :D wtf o_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7354296758846268"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_NB01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here we really need to find the best_model out of this data i got. I don't remember how to see it in the matrix, see Tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average word length extractor, inspired  by https://michelleful.github.io/code-blog/2015/06/20/pipelines/)\n",
    "class AverageWordLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes in dataframe, extracts tweet column, outputs average word length\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def average_word_length(self, tweet):\n",
    "        \"\"\"Helper code to compute average word length of a tweet\"\"\"\n",
    "        return np.mean([len(word) for word in tweet.split()])\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        \"\"\"The workhorse of this feature extractor\"\"\"\n",
    "        # the result of the transform needs to be a 2d array a.k.a. dataframe\n",
    "        # https://stackoverflow.com/a/50713209\n",
    "        result = df.apply(self.average_word_length).to_frame()\n",
    "        print(result)\n",
    "        return result\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        \"\"\"Returns `self` unless something different happens in train and test\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read this blog post on how to construct feature unions :) \n",
    "# http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "\n",
    "# the problem was that our previous pipeline went sorta like this:\n",
    "# create n-grams from text (CountVectorizer) -> tfidf from ngrams (TfidfTransformer) -> average length from ngrams (AvgWLExtractor) ummm :) that wouldn't work... we need to compute the average word length from the original data (tweets / strings).\n",
    "# that's why we have to do these two \"pipelines\" separately => now we just compute the avg from the strings like so...\n",
    "\n",
    "pipeline_NB1 = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', Normalizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('nb_clf', MultinomialNB()) # classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     53469\n",
       "unique       77\n",
       "top          en\n",
       "freq      18764\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {'nb_clf__alpha': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'nb_clf__fit_prior': [True, False]}  #'ngram__ngram_range': [(1, 1), (1, 2), (1, 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=2)]: Done  80 out of  80 | elapsed: 12.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Tweet\n",
      "0        3.900000\n",
      "1       25.000000\n",
      "2        9.750000\n",
      "3        6.000000\n",
      "4        3.750000\n",
      "5        5.142857\n",
      "6        4.190476\n",
      "7        4.523810\n",
      "8       10.800000\n",
      "9        6.200000\n",
      "10       5.000000\n",
      "11      13.500000\n",
      "12      16.500000\n",
      "13       9.500000\n",
      "14       3.000000\n",
      "15       3.250000\n",
      "16       7.333333\n",
      "17       4.833333\n",
      "18       8.133333\n",
      "19       5.000000\n",
      "20      37.000000\n",
      "21       5.000000\n",
      "22      12.000000\n",
      "23       4.421053\n",
      "24       6.388889\n",
      "25      15.666667\n",
      "26      12.000000\n",
      "27       6.333333\n",
      "28       4.777778\n",
      "29      11.500000\n",
      "...           ...\n",
      "53439    7.600000\n",
      "53440    4.684211\n",
      "53441   12.000000\n",
      "53442    8.333333\n",
      "53443    5.000000\n",
      "53444    4.000000\n",
      "53445    9.500000\n",
      "53446    9.300000\n",
      "53447   18.285714\n",
      "53448    6.500000\n",
      "53449  140.000000\n",
      "53450   10.500000\n",
      "53451   12.000000\n",
      "53452    4.769231\n",
      "53453    4.166667\n",
      "53454    4.153846\n",
      "53455    4.400000\n",
      "53456    5.619048\n",
      "53457   10.000000\n",
      "53458   22.500000\n",
      "53459    5.809524\n",
      "53460    5.000000\n",
      "53461    4.950000\n",
      "53462    7.600000\n",
      "53463    5.400000\n",
      "53464   23.200000\n",
      "53465    6.500000\n",
      "53466    8.363636\n",
      "53467    4.571429\n",
      "53468   14.111111\n",
      "\n",
      "[53469 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('ngram_tfidf', Pipeline(memory=None,\n",
       "     steps=[('ngram', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max... transformer_weights=None)), ('nb_clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'nb_clf__alpha': [0.2, 0.6, 0.8, 1.0], 'nb_clf__fit_prior': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_NB1= GridSearchCV(pipeline_NB1, param_grid1, cv=10, n_jobs=2, verbose=1)\n",
    "gs_NB1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Tweet\n",
      "11820  11.500000\n",
      "11022   4.250000\n",
      "11843   8.666667\n",
      "11142   6.333333\n",
      "3044    5.461538\n",
      "3753    9.250000\n",
      "12143   8.571429\n",
      "9873   21.000000\n",
      "7079    4.733333\n",
      "3522    5.571429\n",
      "2427    4.750000\n",
      "8955   20.500000\n",
      "11056   5.000000\n",
      "2266    6.210526\n",
      "10209  17.333333\n",
      "6013    4.625000\n",
      "2235    4.142857\n",
      "4007    4.600000\n",
      "7556    6.444444\n",
      "4080    8.800000\n",
      "10281  11.000000\n",
      "9641   14.333333\n",
      "547     7.400000\n",
      "9551   24.666667\n",
      "5369    4.956522\n",
      "10189  41.000000\n",
      "550     9.000000\n",
      "7831    4.421053\n",
      "1347    4.000000\n",
      "10686   3.500000\n",
      "...          ...\n",
      "8269   10.000000\n",
      "11124   4.625000\n",
      "5627    6.066667\n",
      "1532    4.272727\n",
      "2264    6.250000\n",
      "7119    6.142857\n",
      "6286    3.727273\n",
      "1817    9.875000\n",
      "1497    4.153846\n",
      "2817    6.833333\n",
      "10927   3.500000\n",
      "6646    7.666667\n",
      "9908   13.500000\n",
      "4252    7.562500\n",
      "8662    7.500000\n",
      "9708   14.000000\n",
      "2150    7.500000\n",
      "6090    4.352941\n",
      "7868    7.125000\n",
      "11810   4.200000\n",
      "9268    5.000000\n",
      "9170   20.000000\n",
      "11331   5.000000\n",
      "6446   13.000000\n",
      "1287    7.642857\n",
      "2569    5.500000\n",
      "7286    5.400000\n",
      "13226   8.000000\n",
      "6049    3.700000\n",
      "12008   3.750000\n",
      "\n",
      "[13452 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y_NB1 = gs_NB1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nb_clf__alpha</th>\n",
       "      <th>param_nb_clf__fit_prior</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.450784</td>\n",
       "      <td>1.215598</td>\n",
       "      <td>0.985117</td>\n",
       "      <td>0.315522</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.683605</td>\n",
       "      <td>0.678771</td>\n",
       "      <td>0.683159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974581</td>\n",
       "      <td>0.974478</td>\n",
       "      <td>0.974211</td>\n",
       "      <td>0.974008</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>0.973700</td>\n",
       "      <td>0.973579</td>\n",
       "      <td>0.973873</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.846274</td>\n",
       "      <td>1.214728</td>\n",
       "      <td>0.854151</td>\n",
       "      <td>0.102933</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.631120</td>\n",
       "      <td>0.624022</td>\n",
       "      <td>0.623413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873735</td>\n",
       "      <td>0.874138</td>\n",
       "      <td>0.873673</td>\n",
       "      <td>0.873613</td>\n",
       "      <td>0.873499</td>\n",
       "      <td>0.873507</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.872544</td>\n",
       "      <td>0.873699</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.255900</td>\n",
       "      <td>0.982897</td>\n",
       "      <td>1.107839</td>\n",
       "      <td>0.231791</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.632047</td>\n",
       "      <td>0.622160</td>\n",
       "      <td>0.624160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897408</td>\n",
       "      <td>0.897685</td>\n",
       "      <td>0.897882</td>\n",
       "      <td>0.897112</td>\n",
       "      <td>0.897681</td>\n",
       "      <td>0.897542</td>\n",
       "      <td>0.897453</td>\n",
       "      <td>0.896469</td>\n",
       "      <td>0.897525</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.023044</td>\n",
       "      <td>0.746523</td>\n",
       "      <td>0.908931</td>\n",
       "      <td>0.099870</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.610163</td>\n",
       "      <td>0.604097</td>\n",
       "      <td>0.606049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815954</td>\n",
       "      <td>0.814698</td>\n",
       "      <td>0.815694</td>\n",
       "      <td>0.815583</td>\n",
       "      <td>0.814809</td>\n",
       "      <td>0.814758</td>\n",
       "      <td>0.814909</td>\n",
       "      <td>0.814621</td>\n",
       "      <td>0.815145</td>\n",
       "      <td>0.000442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.565887</td>\n",
       "      <td>1.911244</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>0.152788</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.591246</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.584578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772348</td>\n",
       "      <td>0.772009</td>\n",
       "      <td>0.771950</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.771056</td>\n",
       "      <td>0.771444</td>\n",
       "      <td>0.771332</td>\n",
       "      <td>0.770924</td>\n",
       "      <td>0.771562</td>\n",
       "      <td>0.000422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.472430</td>\n",
       "      <td>0.848787</td>\n",
       "      <td>0.986116</td>\n",
       "      <td>0.202387</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.537463</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.530246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704778</td>\n",
       "      <td>0.704152</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.704072</td>\n",
       "      <td>0.703287</td>\n",
       "      <td>0.703077</td>\n",
       "      <td>0.703307</td>\n",
       "      <td>0.703718</td>\n",
       "      <td>0.703841</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>2.288363</td>\n",
       "      <td>1.149593</td>\n",
       "      <td>0.388676</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.509829</td>\n",
       "      <td>0.504842</td>\n",
       "      <td>0.502614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615676</td>\n",
       "      <td>0.614619</td>\n",
       "      <td>0.615885</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.615282</td>\n",
       "      <td>0.615119</td>\n",
       "      <td>0.613804</td>\n",
       "      <td>0.614683</td>\n",
       "      <td>0.615108</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.163292</td>\n",
       "      <td>1.994885</td>\n",
       "      <td>1.202061</td>\n",
       "      <td>0.620069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.489800</td>\n",
       "      <td>0.485661</td>\n",
       "      <td>0.484317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504978</td>\n",
       "      <td>0.503720</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.503678</td>\n",
       "      <td>0.504508</td>\n",
       "      <td>0.504041</td>\n",
       "      <td>0.502181</td>\n",
       "      <td>0.504133</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1      13.450784      1.215598         0.985117        0.315522   \n",
       "3      11.846274      1.214728         0.854151        0.102933   \n",
       "0      13.255900      0.982897         1.107839        0.231791   \n",
       "5      12.023044      0.746523         0.908931        0.099870   \n",
       "7      13.565887      1.911244         0.987051        0.152788   \n",
       "2      12.472430      0.848787         0.986116        0.202387   \n",
       "4      13.750000      2.288363         1.149593        0.388676   \n",
       "6      13.163292      1.994885         1.202061        0.620069   \n",
       "\n",
       "  param_nb_clf__alpha param_nb_clf__fit_prior  \\\n",
       "1                 0.2                   False   \n",
       "3                 0.6                   False   \n",
       "0                 0.2                    True   \n",
       "5                 0.8                   False   \n",
       "7                   1                   False   \n",
       "2                 0.6                    True   \n",
       "4                 0.8                    True   \n",
       "6                   1                    True   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "1  {'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': Fa...           0.683605   \n",
       "3  {'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': Fa...           0.631120   \n",
       "0  {'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': True}           0.632047   \n",
       "5  {'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': Fa...           0.610163   \n",
       "7  {'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': Fa...           0.591246   \n",
       "2  {'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': True}           0.537463   \n",
       "4  {'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': True}           0.509829   \n",
       "6  {'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': True}           0.489800   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  split2_train_score  \\\n",
       "1           0.678771           0.683159  ...            0.974581   \n",
       "3           0.624022           0.623413  ...            0.873735   \n",
       "0           0.622160           0.624160  ...            0.897408   \n",
       "5           0.604097           0.606049  ...            0.815954   \n",
       "7           0.586592           0.584578  ...            0.772348   \n",
       "2           0.533333           0.530246  ...            0.704778   \n",
       "4           0.504842           0.502614  ...            0.615676   \n",
       "6           0.485661           0.484317  ...            0.504978   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "1            0.974478            0.974211            0.974008   \n",
       "3            0.874138            0.873673            0.873613   \n",
       "0            0.897685            0.897882            0.897112   \n",
       "5            0.814698            0.815694            0.815583   \n",
       "7            0.772009            0.771950            0.771369   \n",
       "2            0.704152            0.704017            0.704072   \n",
       "4            0.614619            0.615885            0.615188   \n",
       "6            0.503720            0.504167            0.503678   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "1            0.974218            0.973700            0.973579   \n",
       "3            0.873499            0.873507            0.873214   \n",
       "0            0.897681            0.897542            0.897453   \n",
       "5            0.814809            0.814758            0.814909   \n",
       "7            0.771056            0.771444            0.771332   \n",
       "2            0.703287            0.703077            0.703307   \n",
       "4            0.615282            0.615119            0.613804   \n",
       "6            0.504508            0.504041            0.502181   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  \n",
       "1            0.973873          0.974189         0.000385  \n",
       "3            0.872544          0.873699         0.000599  \n",
       "0            0.896469          0.897525         0.000492  \n",
       "5            0.814621          0.815145         0.000442  \n",
       "7            0.770924          0.771562         0.000422  \n",
       "2            0.703718          0.703841         0.000480  \n",
       "4            0.614683          0.615108         0.000572  \n",
       "6            0.504133          0.503966         0.000693  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result = pd.DataFrame.from_dict(gs_NB1.cv_results_)\n",
    "grid_result.sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best model is with an alpha of 0.2 and a fit_prior: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Tweet\n",
      "0        3.900000\n",
      "1       25.000000\n",
      "2        9.750000\n",
      "3        6.000000\n",
      "4        3.750000\n",
      "5        5.142857\n",
      "6        4.190476\n",
      "7        4.523810\n",
      "8       10.800000\n",
      "9        6.200000\n",
      "10       5.000000\n",
      "11      13.500000\n",
      "12      16.500000\n",
      "13       9.500000\n",
      "14       3.000000\n",
      "15       3.250000\n",
      "16       7.333333\n",
      "17       4.833333\n",
      "18       8.133333\n",
      "19       5.000000\n",
      "20      37.000000\n",
      "21       5.000000\n",
      "22      12.000000\n",
      "23       4.421053\n",
      "24       6.388889\n",
      "25      15.666667\n",
      "26      12.000000\n",
      "27       6.333333\n",
      "28       4.777778\n",
      "29      11.500000\n",
      "...           ...\n",
      "53439    7.600000\n",
      "53440    4.684211\n",
      "53441   12.000000\n",
      "53442    8.333333\n",
      "53443    5.000000\n",
      "53444    4.000000\n",
      "53445    9.500000\n",
      "53446    9.300000\n",
      "53447   18.285714\n",
      "53448    6.500000\n",
      "53449  140.000000\n",
      "53450   10.500000\n",
      "53451   12.000000\n",
      "53452    4.769231\n",
      "53453    4.166667\n",
      "53454    4.153846\n",
      "53455    4.400000\n",
      "53456    5.619048\n",
      "53457   10.000000\n",
      "53458   22.500000\n",
      "53459    5.809524\n",
      "53460    5.000000\n",
      "53461    4.950000\n",
      "53462    7.600000\n",
      "53463    5.400000\n",
      "53464   23.200000\n",
      "53465    6.500000\n",
      "53466    8.363636\n",
      "53467    4.571429\n",
      "53468   14.111111\n",
      "\n",
      "[53469 rows x 1 columns]\n",
      "           Tweet\n",
      "11820  11.500000\n",
      "11022   4.250000\n",
      "11843   8.666667\n",
      "11142   6.333333\n",
      "3044    5.461538\n",
      "3753    9.250000\n",
      "12143   8.571429\n",
      "9873   21.000000\n",
      "7079    4.733333\n",
      "3522    5.571429\n",
      "2427    4.750000\n",
      "8955   20.500000\n",
      "11056   5.000000\n",
      "2266    6.210526\n",
      "10209  17.333333\n",
      "6013    4.625000\n",
      "2235    4.142857\n",
      "4007    4.600000\n",
      "7556    6.444444\n",
      "4080    8.800000\n",
      "10281  11.000000\n",
      "9641   14.333333\n",
      "547     7.400000\n",
      "9551   24.666667\n",
      "5369    4.956522\n",
      "10189  41.000000\n",
      "550     9.000000\n",
      "7831    4.421053\n",
      "1347    4.000000\n",
      "10686   3.500000\n",
      "...          ...\n",
      "8269   10.000000\n",
      "11124   4.625000\n",
      "5627    6.066667\n",
      "1532    4.272727\n",
      "2264    6.250000\n",
      "7119    6.142857\n",
      "6286    3.727273\n",
      "1817    9.875000\n",
      "1497    4.153846\n",
      "2817    6.833333\n",
      "10927   3.500000\n",
      "6646    7.666667\n",
      "9908   13.500000\n",
      "4252    7.562500\n",
      "8662    7.500000\n",
      "9708   14.000000\n",
      "2150    7.500000\n",
      "6090    4.352941\n",
      "7868    7.125000\n",
      "11810   4.200000\n",
      "9268    5.000000\n",
      "9170   20.000000\n",
      "11331   5.000000\n",
      "6446   13.000000\n",
      "1287    7.642857\n",
      "2569    5.500000\n",
      "7286    5.400000\n",
      "13226   8.000000\n",
      "6049    3.700000\n",
      "12008   3.750000\n",
      "\n",
      "[13452 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "best_model = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', Normalizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('nb_clf', MultinomialNB(alpha=0.2, fit_prior=False)) # classifier\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "best_model_prediction = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885964912280702"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, best_model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885964912280702"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_NB1)\n",
    "# not rly sure why the accuracy is lower than NB01, kinda confused bout this :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  16 out of  16 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7331251858459709"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test without avg but with a nested FeatureUnion with 1 feature (pipeline)\n",
    "# This should have the same accuracy as NB01, and it does... which implies that the pipeline/featureunion thing is correct. I'd say we have to look into hyperparams to fix the accuracy.\n",
    "pipeline_NB2 = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('nb_clf', MultinomialNB()) # classifier\n",
    "])\n",
    "\n",
    "gs_NB2= GridSearchCV(pipeline_NB2, param_grid1, cv=10, n_jobs=2, verbose=1) # same param_grid as NB1\n",
    "gs_NB2.fit(X_train, y_train)\n",
    "y_NB2 = gs_NB2.predict(X_test)\n",
    "accuracy_score(y_test, y_NB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a try with SGD, same features!\n",
    "pipeline_SGD = Pipeline([\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer()), \n",
    "        ])),\n",
    "        ('ave', AverageWordLengthExtractor())\n",
    "    ])),\n",
    "    ('SGD_clf', SGDClassifier())# classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_SGD = {'SGD_clf__loss': ['hinge', 'log'],\n",
    "                  'SGD_clf__penalty': ['none', 'l1', 'l2'],\n",
    "                  'SGD_clf__max_iter': [50, 100, 500, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_SGD = GridSearchCV(pipeline_SGD, grid_param_SGD, cv=10, n_jobs=2, verbose=1)\n",
    "gs_SGD.fit(X_train, y_train)\n",
    "##NOTE: it crashed^s at the same point: could not convert string to float: 'á‰á¶áŸ†ááŸ’á“á¶áŸ†á•áŸ’áá¶áŸáŸá¶á™ááŸ’á›á¶áŸ†á–áŸá€á¡á¾á„á‚áŸá‰á›áŸ‚á„á…á„áŸ‹á…á„áŸ‹á€áŸ’ášáŸ„á€á á¾á™....'\n",
    "#Maybe some problem with the encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SGD = gs_SGD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609277430865299"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP_CLF = 'MLP_clf'\n",
    "\n",
    "pipeline_MLP = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', Normalizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    (MLP_CLF, MLPClassifier()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_MLP = { MLP_CLF + '__hidden_layer_sizes': [(4, 3), (5, 3)],\n",
    "                   MLP_CLF + '__activation': ['tanh', 'relu'],\n",
    "                   MLP_CLF + '__solver': ['sgd', 'adam'],\n",
    "                   MLP_CLF + '__max_iter': [50],\n",
    "                   MLP_CLF + '__momentum': [0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "gs_MLP = GridSearchCV(pipeline_MLP, grid_param_MLP, cv=10, n_jobs=2, verbose=1)\n",
    "gs_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
