{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# File paths\n",
    "DATA_FP = \"./data/\" # Data file path\n",
    "TWEETS_FP = DATA_FP + \"tweets.json\"\n",
    "TRAIN_DEV_FP = DATA_FP + \"labels-train+dev.tsv\"\n",
    "TEST_FP = DATA_FP + \"labels-test.tsv\"\n",
    "\n",
    "# Column names\n",
    "COL_ID = 'ID'\n",
    "COL_TWEET = 'Tweet'\n",
    "COL_LABEL = 'Label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data\n",
    "\n",
    "## Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the first file (Tweets)\n",
    "tweets = []\n",
    "with open(TWEETS_FP, 'r') as tweets_fh:  # Tweets file handle\n",
    "    for line in tweets_fh:   # put each line in a list of lines\n",
    "        j_content = json.loads(line)\n",
    "        tweets.append(j_content)\n",
    "\n",
    "tweets = pd.DataFrame(tweets, columns=[COL_ID, COL_TWEET])  # make a dataframe out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483885347374243841</td>\n",
       "      <td>اللهم أفرح قلبي وقلب من أحب وأغسل أحزاننا وهمو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484023414781263872</td>\n",
       "      <td>إضغط على منطقتك يتبين لك كم يتبقى من الوقت عن ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484026168300273664</td>\n",
       "      <td>اللَّهٌمَّ صَلِّ وَسَلِّمْ عَلىٰ نَبِيِّنَآ مُ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483819942878650369</td>\n",
       "      <td>@Dinaa_ElAraby اها يا بيبي والله اتهرست علي تو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>483793769079123971</td>\n",
       "      <td>• افضل كتاب قرأته هو : أمي (ابراهام لنكولن)\\n🌹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>483934868070350849</td>\n",
       "      <td>@hudc7721 انتظري اجل \\nخيره لك يارب 😘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>483863369972473856</td>\n",
       "      <td>(وإن تجهر بالقول فإنه يعلم السر وأخفى) [طه:7]\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>483871567311413248</td>\n",
       "      <td>ﺧﻟك ﻋزﯾز آﻟﻧﻓس ﻟۈ ﮪﻣۈﻣك ﺟﺑآللاﭠﺷﺷﮐي ﻟﻟﻧآﺳس ﻣن ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>483931429902884864</td>\n",
       "      <td>عشان الجنّة أجمل ؟  الله يبعدنا عن كل ذنب مايخ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>483773756897124352</td>\n",
       "      <td>توجيه كيفية تثبيت البرامج الثابتة ROM التحميل ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>483986544865210368</td>\n",
       "      <td>@dana_mahmod هههههه ماشاء الله حكيك</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>483873243598565376</td>\n",
       "      <td>@anabs_anabs @Rayedrd أنشهد بس فيه بعض الناس ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>483790646176935936</td>\n",
       "      <td>{يعلمون ظاهرا من الحياة الدنيا وهم عن الآخرة ه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>483911764674105344</td>\n",
       "      <td>http://t.co/4KAHaNd4an سيدي إيفني : شكاية أجنب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>483798014239072256</td>\n",
       "      <td>أعجبتني هذه الـ #keek http://t.co/vORaVpTnJ9 ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>483954767727980544</td>\n",
       "      <td>(إن  الذين  كفروا  من  أهل  الكتاب  والمشركين ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>484025624076374016</td>\n",
       "      <td>ان كان غيري عن هوى قلبي اغناك، يغنيني الله عن ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>483764454283558912</td>\n",
       "      <td>#بحترم\\nالشخص اللي ماشي بمبدأ اللي مردهوش على ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>483918976129302528</td>\n",
       "      <td>@uu44pp @abunawafeid @3ajel_news الصوره هاذي ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>483811483906625536</td>\n",
       "      <td>حتى الندم على المعصيه تؤجر عليه - سبحانك يالله...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>483782119827582977</td>\n",
       "      <td>اللهم قدر لنا الفرح بكل اشكاله ، انت الكريم ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>483780914452111360</td>\n",
       "      <td>{وأنه هو أغنى وأقنى} [النجم:48]\\nhttp://t.co/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>483975567989956608</td>\n",
       "      <td>@AlwaaKsa وش حطيتي ؟؟\\nانا اقول تيفاني</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>483938071646584834</td>\n",
       "      <td>حسبي الله لا إله إلا هو عليه توكلت وهو ربُّ ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>483782693868433408</td>\n",
       "      <td>#غزه_تحت_القصف\\n\\nداعش أخواني حيل عندكم بالمدن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>484025449207451648</td>\n",
       "      <td>انقلاب حافلة في “قليّب خضر” بالجوف الى إصابة 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>483942359281836032</td>\n",
       "      <td>@sarah66600  اي موقف تتكلمين عنه .. قصدك ملايي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>483770900127285248</td>\n",
       "      <td>ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>483866174556352512</td>\n",
       "      <td>@ana_bent_gad3a الو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>483770765985083392</td>\n",
       "      <td>يا ابو سلو عرفتني</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66891</th>\n",
       "      <td>493381795287531520</td>\n",
       "      <td>這個週末兩天都跟 Navel 很有緣...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66892</th>\n",
       "      <td>493132254579675138</td>\n",
       "      <td>{CWB} 桃園縣 一週天氣預報(07/27 05:00發布): 07/27 白天 溫度:2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66893</th>\n",
       "      <td>488630113211518976</td>\n",
       "      <td>其實我很想問，噗浪怎麼鎖回應然後又開啟的#### http://t.co/sQBh6jmVoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66894</th>\n",
       "      <td>486899420798009344</td>\n",
       "      <td>-\\n賀文p14\\n台灣訪問你地\\n其他成員話你係全隊最天不怕地不怕果陣\\n我林： 如果你去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66895</th>\n",
       "      <td>492664113739231232</td>\n",
       "      <td>我已收获 817 食物！http://t.co/JghsHr4QV4 #iphone, #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66896</th>\n",
       "      <td>487199504416768000</td>\n",
       "      <td>基隆唯一一家！ http://t.co/7f6yE7zKo2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66897</th>\n",
       "      <td>490456582136676352</td>\n",
       "      <td>注个销都能死机……</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66898</th>\n",
       "      <td>488488642370080769</td>\n",
       "      <td>全平台翻墙指南（PC＋安卓＋iOS+Mac+Linux）[2014.7更新] https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66899</th>\n",
       "      <td>491992347278725120</td>\n",
       "      <td>『 』 免費的女性向戀愛遊戲★想和哥哥假結婚看看嗎？　https://t.co/YOUkKU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66900</th>\n",
       "      <td>491661312745676800</td>\n",
       "      <td>我正在玩「神女控」，一个结合漂亮卡片战斗和迷你城市建造的游戏！一起参与战斗去冒险吧！ htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66901</th>\n",
       "      <td>489025682597363714</td>\n",
       "      <td>现在的常规上班时间基本稳定在早11晚9或10……</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66902</th>\n",
       "      <td>494650331528433666</td>\n",
       "      <td>#204.7.25 花蓮區漁會 http://t.co/yOukLkXwCr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66903</th>\n",
       "      <td>494331450800361473</td>\n",
       "      <td>@shota_nuke 好做，重点是捣碎和蒸，嫌麻烦就上压力锅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66904</th>\n",
       "      <td>485752157937741824</td>\n",
       "      <td>@makzihau 当然是史地啦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66905</th>\n",
       "      <td>490766951061270528</td>\n",
       "      <td>请别以为你有多难忘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66906</th>\n",
       "      <td>484328282582577152</td>\n",
       "      <td>@EmmaKongms 所以我地要叫朋友來開account 先，緊急情況要識轉台睇Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66907</th>\n",
       "      <td>486841789866070016</td>\n",
       "      <td>@hundtw 不要眯啦 來喝一杯啦 #喂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66908</th>\n",
       "      <td>484996827121344512</td>\n",
       "      <td>《音速經紀》於背地裡支援音速子 引導玩家的 “音樂女神”「繆斯」登場 http://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66909</th>\n",
       "      <td>491731230618963968</td>\n",
       "      <td>@immei0125 空调呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66910</th>\n",
       "      <td>494627004973465601</td>\n",
       "      <td>Ace of Base - Unspeakable (Junk &amp;amp; Function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66911</th>\n",
       "      <td>493305178523963392</td>\n",
       "      <td>那就点64个赞哈 RT @ls691208: 大酥不要好人卡，好人卡最后都木有好下场！RT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66912</th>\n",
       "      <td>484586108282736641</td>\n",
       "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66913</th>\n",
       "      <td>494052509619482625</td>\n",
       "      <td>占领美帝  http://t.co/nBd1Rvy8WK http://t.co/Cy2UK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66914</th>\n",
       "      <td>485273015035244545</td>\n",
       "      <td>我取得了一项新成就：`管理员`.尝试在iPad版Tribez游戏中打败我吧！http://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66915</th>\n",
       "      <td>484912347106926592</td>\n",
       "      <td>热点文章：《《京城81号》吴镇宇特辑—在线播放—优酷网，视频高清在线观看》 http://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66916</th>\n",
       "      <td>486035976079147009</td>\n",
       "      <td>大立光2450盤中新高 台股收漲9520 http://t.co/T1x9EhD7mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66917</th>\n",
       "      <td>486299665873108992</td>\n",
       "      <td>真佛宗大马各分堂中元节法会活动，欢迎护持 !\\n\\n农历七月的『中元節』即将到来。农历七月是...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66918</th>\n",
       "      <td>490364709082652673</td>\n",
       "      <td>我已收获 2,211 食物！http://t.co/Fo8dtabIw7 #android,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66919</th>\n",
       "      <td>484672019091300352</td>\n",
       "      <td>精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66920</th>\n",
       "      <td>491155187755515904</td>\n",
       "      <td>一分鐘世界盃！http://t.co/yEvaMrp7ki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                                              Tweet\n",
       "0      483885347374243841  اللهم أفرح قلبي وقلب من أحب وأغسل أحزاننا وهمو...\n",
       "1      484023414781263872  إضغط على منطقتك يتبين لك كم يتبقى من الوقت عن ...\n",
       "2      484026168300273664  اللَّهٌمَّ صَلِّ وَسَلِّمْ عَلىٰ نَبِيِّنَآ مُ...\n",
       "3      483819942878650369  @Dinaa_ElAraby اها يا بيبي والله اتهرست علي تو...\n",
       "4      483793769079123971  • افضل كتاب قرأته هو : أمي (ابراهام لنكولن)\\n🌹...\n",
       "5      483934868070350849              @hudc7721 انتظري اجل \\nخيره لك يارب 😘\n",
       "6      483863369972473856  (وإن تجهر بالقول فإنه يعلم السر وأخفى) [طه:7]\\...\n",
       "7      483871567311413248  ﺧﻟك ﻋزﯾز آﻟﻧﻓس ﻟۈ ﮪﻣۈﻣك ﺟﺑآللاﭠﺷﺷﮐي ﻟﻟﻧآﺳس ﻣن ...\n",
       "8      483931429902884864  عشان الجنّة أجمل ؟  الله يبعدنا عن كل ذنب مايخ...\n",
       "9      483773756897124352  توجيه كيفية تثبيت البرامج الثابتة ROM التحميل ...\n",
       "10     483986544865210368                @dana_mahmod هههههه ماشاء الله حكيك\n",
       "11     483873243598565376  @anabs_anabs @Rayedrd أنشهد بس فيه بعض الناس ل...\n",
       "12     483790646176935936  {يعلمون ظاهرا من الحياة الدنيا وهم عن الآخرة ه...\n",
       "13     483911764674105344  http://t.co/4KAHaNd4an سيدي إيفني : شكاية أجنب...\n",
       "14     483798014239072256  أعجبتني هذه الـ #keek http://t.co/vORaVpTnJ9 ر...\n",
       "15     483954767727980544  (إن  الذين  كفروا  من  أهل  الكتاب  والمشركين ...\n",
       "16     484025624076374016  ان كان غيري عن هوى قلبي اغناك، يغنيني الله عن ...\n",
       "17     483764454283558912  #بحترم\\nالشخص اللي ماشي بمبدأ اللي مردهوش على ...\n",
       "18     483918976129302528  @uu44pp @abunawafeid @3ajel_news الصوره هاذي ا...\n",
       "19     483811483906625536  حتى الندم على المعصيه تؤجر عليه - سبحانك يالله...\n",
       "20     483782119827582977  اللهم قدر لنا الفرح بكل اشكاله ، انت الكريم ال...\n",
       "21     483780914452111360  {وأنه هو أغنى وأقنى} [النجم:48]\\nhttp://t.co/i...\n",
       "22     483975567989956608             @AlwaaKsa وش حطيتي ؟؟\\nانا اقول تيفاني\n",
       "23     483938071646584834  حسبي الله لا إله إلا هو عليه توكلت وهو ربُّ ال...\n",
       "24     483782693868433408  #غزه_تحت_القصف\\n\\nداعش أخواني حيل عندكم بالمدن...\n",
       "25     484025449207451648  انقلاب حافلة في “قليّب خضر” بالجوف الى إصابة 7...\n",
       "26     483942359281836032  @sarah66600  اي موقف تتكلمين عنه .. قصدك ملايي...\n",
       "27     483770900127285248  ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...\n",
       "28     483866174556352512                                @ana_bent_gad3a الو\n",
       "29     483770765985083392                                  يا ابو سلو عرفتني\n",
       "...                   ...                                                ...\n",
       "66891  493381795287531520                              這個週末兩天都跟 Navel 很有緣...\n",
       "66892  493132254579675138  {CWB} 桃園縣 一週天氣預報(07/27 05:00發布): 07/27 白天 溫度:2...\n",
       "66893  488630113211518976    其實我很想問，噗浪怎麼鎖回應然後又開啟的#### http://t.co/sQBh6jmVoW\n",
       "66894  486899420798009344  -\\n賀文p14\\n台灣訪問你地\\n其他成員話你係全隊最天不怕地不怕果陣\\n我林： 如果你去...\n",
       "66895  492664113739231232  我已收获 817 食物！http://t.co/JghsHr4QV4 #iphone, #i...\n",
       "66896  487199504416768000                     基隆唯一一家！ http://t.co/7f6yE7zKo2\n",
       "66897  490456582136676352                                          注个销都能死机……\n",
       "66898  488488642370080769  全平台翻墙指南（PC＋安卓＋iOS+Mac+Linux）[2014.7更新] https:/...\n",
       "66899  491992347278725120  『 』 免費的女性向戀愛遊戲★想和哥哥假結婚看看嗎？　https://t.co/YOUkKU...\n",
       "66900  491661312745676800  我正在玩「神女控」，一个结合漂亮卡片战斗和迷你城市建造的游戏！一起参与战斗去冒险吧！ htt...\n",
       "66901  489025682597363714                           现在的常规上班时间基本稳定在早11晚9或10……\n",
       "66902  494650331528433666             #204.7.25 花蓮區漁會 http://t.co/yOukLkXwCr\n",
       "66903  494331450800361473                    @shota_nuke 好做，重点是捣碎和蒸，嫌麻烦就上压力锅\n",
       "66904  485752157937741824                                   @makzihau 当然是史地啦\n",
       "66905  490766951061270528                                          请别以为你有多难忘\n",
       "66906  484328282582577152   @EmmaKongms 所以我地要叫朋友來開account 先，緊急情況要識轉台睇Twitter\n",
       "66907  486841789866070016                              @hundtw 不要眯啦 來喝一杯啦 #喂\n",
       "66908  484996827121344512  《音速經紀》於背地裡支援音速子 引導玩家的 “音樂女神”「繆斯」登場 http://t.co...\n",
       "66909  491731230618963968                                     @immei0125 空调呢\n",
       "66910  494627004973465601  Ace of Base - Unspeakable (Junk &amp; Function...\n",
       "66911  493305178523963392  那就点64个赞哈 RT @ls691208: 大酥不要好人卡，好人卡最后都木有好下场！RT ...\n",
       "66912  484586108282736641                  @Official_SABC1 Moloooo nakuwe!!!\n",
       "66913  494052509619482625  占领美帝  http://t.co/nBd1Rvy8WK http://t.co/Cy2UK...\n",
       "66914  485273015035244545  我取得了一项新成就：`管理员`.尝试在iPad版Tribez游戏中打败我吧！http://t...\n",
       "66915  484912347106926592  热点文章：《《京城81号》吴镇宇特辑—在线播放—优酷网，视频高清在线观看》 http://t...\n",
       "66916  486035976079147009        大立光2450盤中新高 台股收漲9520 http://t.co/T1x9EhD7mi\n",
       "66917  486299665873108992  真佛宗大马各分堂中元节法会活动，欢迎护持 !\\n\\n农历七月的『中元節』即将到来。农历七月是...\n",
       "66918  490364709082652673  我已收获 2,211 食物！http://t.co/Fo8dtabIw7 #android,...\n",
       "66919  484672019091300352  精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神...\n",
       "66920  491155187755515904                      一分鐘世界盃！http://t.co/yEvaMrp7ki\n",
       "\n",
       "[66921 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets # looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with both label documents\n",
    "\n",
    "train_dev_labels = pd.read_csv(TRAIN_DEV_FP, sep='\\t', header=None, names=[COL_LABEL, COL_ID])\n",
    "test_labels = pd.read_csv(TEST_FP, sep='\\t', header=None, names=[COL_LABEL, COL_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ar</td>\n",
       "      <td>483762194908479488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ar</td>\n",
       "      <td>483762916097654784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ar</td>\n",
       "      <td>483764828784582656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ar</td>\n",
       "      <td>483765526683209728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ar</td>\n",
       "      <td>483768342315282432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ar</td>\n",
       "      <td>483770765985083392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ar</td>\n",
       "      <td>483770900127285248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ar</td>\n",
       "      <td>483770997892345857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ar</td>\n",
       "      <td>483773690769702912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ar</td>\n",
       "      <td>483773756897124352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ar</td>\n",
       "      <td>483777578163908609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ar</td>\n",
       "      <td>483780914452111360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ar</td>\n",
       "      <td>483782119827582977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ar</td>\n",
       "      <td>483782693868433408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ar</td>\n",
       "      <td>483783499174772736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ar</td>\n",
       "      <td>483783505445265409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ar</td>\n",
       "      <td>483790646176935936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ar</td>\n",
       "      <td>483793769079123971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ar</td>\n",
       "      <td>483796613656109056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ar</td>\n",
       "      <td>483796979063848960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ar</td>\n",
       "      <td>483799673044344832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ar</td>\n",
       "      <td>483802793459736576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ar</td>\n",
       "      <td>483805955852107776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ar</td>\n",
       "      <td>483807295134900224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ar</td>\n",
       "      <td>483811483906625536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ar</td>\n",
       "      <td>483818326599426048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ar</td>\n",
       "      <td>483819942878650369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ar</td>\n",
       "      <td>483824293952749568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ar</td>\n",
       "      <td>483831683653697537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ar</td>\n",
       "      <td>483848516356562945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96384</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>492581164196978690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96385</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>492602588031090689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96386</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>492664113739231232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96387</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493280795314753536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96388</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493305178523963392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96389</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493466690378686466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96390</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>493645244248756224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96391</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494052509619482625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96392</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494068544120705025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96393</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494331450800361473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96394</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494627004973465601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96395</th>\n",
       "      <td>zh-CN</td>\n",
       "      <td>494730046020403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96396</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>483849852225196032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96397</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>484245222742704128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96398</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>484328282582577152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96399</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>484996827121344512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96400</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>486035976079147009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96401</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>486841789866070016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96402</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>486899420798009344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96403</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>488630113211518976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96404</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>489697736854634496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96405</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>490149224416174081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96406</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>490514766029279233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96407</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>490667138081099776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96408</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>491155187755515904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96409</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>492349820346974209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96410</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>493132254579675138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96411</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>493381795287531520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96412</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>493643635632930816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96413</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>494059705564553216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96414 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                  ID\n",
       "0        ar   483762194908479488\n",
       "1         ar  483762916097654784\n",
       "2         ar  483764828784582656\n",
       "3         ar  483765526683209728\n",
       "4         ar  483768342315282432\n",
       "5         ar  483770765985083392\n",
       "6         ar  483770900127285248\n",
       "7         ar  483770997892345857\n",
       "8         ar  483773690769702912\n",
       "9         ar  483773756897124352\n",
       "10        ar  483777578163908609\n",
       "11        ar  483780914452111360\n",
       "12        ar  483782119827582977\n",
       "13        ar  483782693868433408\n",
       "14        ar  483783499174772736\n",
       "15        ar  483783505445265409\n",
       "16        ar  483790646176935936\n",
       "17        ar  483793769079123971\n",
       "18        ar  483796613656109056\n",
       "19        ar  483796979063848960\n",
       "20        ar  483799673044344832\n",
       "21        ar  483802793459736576\n",
       "22        ar  483805955852107776\n",
       "23        ar  483807295134900224\n",
       "24        ar  483811483906625536\n",
       "25        ar  483818326599426048\n",
       "26        ar  483819942878650369\n",
       "27        ar  483824293952749568\n",
       "28        ar  483831683653697537\n",
       "29        ar  483848516356562945\n",
       "...      ...                 ...\n",
       "96384  zh-CN  492581164196978690\n",
       "96385  zh-CN  492602588031090689\n",
       "96386  zh-CN  492664113739231232\n",
       "96387  zh-CN  493280795314753536\n",
       "96388  zh-CN  493305178523963392\n",
       "96389  zh-CN  493466690378686466\n",
       "96390  zh-CN  493645244248756224\n",
       "96391  zh-CN  494052509619482625\n",
       "96392  zh-CN  494068544120705025\n",
       "96393  zh-CN  494331450800361473\n",
       "96394  zh-CN  494627004973465601\n",
       "96395  zh-CN  494730046020403200\n",
       "96396  zh-TW  483849852225196032\n",
       "96397  zh-TW  484245222742704128\n",
       "96398  zh-TW  484328282582577152\n",
       "96399  zh-TW  484996827121344512\n",
       "96400  zh-TW  486035976079147009\n",
       "96401  zh-TW  486841789866070016\n",
       "96402  zh-TW  486899420798009344\n",
       "96403  zh-TW  488630113211518976\n",
       "96404  zh-TW  489697736854634496\n",
       "96405  zh-TW  490149224416174081\n",
       "96406  zh-TW  490514766029279233\n",
       "96407  zh-TW  490667138081099776\n",
       "96408  zh-TW  491155187755515904\n",
       "96409  zh-TW  492349820346974209\n",
       "96410  zh-TW  493132254579675138\n",
       "96411  zh-TW  493381795287531520\n",
       "96412  zh-TW  493643635632930816\n",
       "96413  zh-TW  494059705564553216\n",
       "\n",
       "[96414 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_labels # looks about right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[COL_ID]=tweets[COL_ID].astype(int) # to allow for merge, need the same type\n",
    "\n",
    "train_dev_data = pd.merge(tweets, train_dev_labels, on=COL_ID) # merge by ID\n",
    "test_data = pd.merge(tweets, test_labels, on=COL_ID) # merge by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483885347374243841</td>\n",
       "      <td>اللهم أفرح قلبي وقلب من أحب وأغسل أحزاننا وهمو...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484023414781263872</td>\n",
       "      <td>إضغط على منطقتك يتبين لك كم يتبقى من الوقت عن ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484026168300273664</td>\n",
       "      <td>اللَّهٌمَّ صَلِّ وَسَلِّمْ عَلىٰ نَبِيِّنَآ مُ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483819942878650369</td>\n",
       "      <td>@Dinaa_ElAraby اها يا بيبي والله اتهرست علي تو...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>483793769079123971</td>\n",
       "      <td>• افضل كتاب قرأته هو : أمي (ابراهام لنكولن)\\n🌹...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                              Tweet Label\n",
       "0  483885347374243841  اللهم أفرح قلبي وقلب من أحب وأغسل أحزاننا وهمو...    ar\n",
       "1  484023414781263872  إضغط على منطقتك يتبين لك كم يتبقى من الوقت عن ...    ar\n",
       "2  484026168300273664  اللَّهٌمَّ صَلِّ وَسَلِّمْ عَلىٰ نَبِيِّنَآ مُ...    ar\n",
       "3  483819942878650369  @Dinaa_ElAraby اها يا بيبي والله اتهرست علي تو...    ar\n",
       "4  483793769079123971  • افضل كتاب قرأته هو : أمي (ابراهام لنكولن)\\n🌹...    ar"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13447</th>\n",
       "      <td>491992347278725120</td>\n",
       "      <td>『 』 免費的女性向戀愛遊戲★想和哥哥假結婚看看嗎？　https://t.co/YOUkKU...</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13448</th>\n",
       "      <td>494650331528433666</td>\n",
       "      <td>#204.7.25 花蓮區漁會 http://t.co/yOukLkXwCr</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13449</th>\n",
       "      <td>485752157937741824</td>\n",
       "      <td>@makzihau 当然是史地啦</td>\n",
       "      <td>zh-CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13450</th>\n",
       "      <td>484586108282736641</td>\n",
       "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
       "      <td>zu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13451</th>\n",
       "      <td>484672019091300352</td>\n",
       "      <td>精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神...</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                                              Tweet  \\\n",
       "13447  491992347278725120  『 』 免費的女性向戀愛遊戲★想和哥哥假結婚看看嗎？　https://t.co/YOUkKU...   \n",
       "13448  494650331528433666             #204.7.25 花蓮區漁會 http://t.co/yOukLkXwCr   \n",
       "13449  485752157937741824                                   @makzihau 当然是史地啦   \n",
       "13450  484586108282736641                  @Official_SABC1 Moloooo nakuwe!!!   \n",
       "13451  484672019091300352  精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神統一精神...   \n",
       "\n",
       "       Label  \n",
       "13447  zh-TW  \n",
       "13448  zh-TW  \n",
       "13449  zh-CN  \n",
       "13450     zu  \n",
       "13451  zh-TW  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_n_shuffle(data):\n",
    "    data_no_na = data.dropna().copy()\n",
    "    return data_no_na.sample(frac=1)\n",
    "\n",
    "train_dev_set = drop_n_shuffle(train_dev_data).reset_index(drop = True)\n",
    "test_set = drop_n_shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ID                                              Tweet Label\n",
      "0  490917308399763457   \"Hold on I'm going to brush a horse.\" -Willow 😂😂    en\n",
      "1  493347986013822976  @atsushi022518 \\nあっちゃん、てんねんじゃないよ。天才だよ💫おさとうはまちが...    ja\n",
      "2  484938267268091904         Упругое тело… (18+) http://t.co/xpXN8rDqED    ru\n",
      "3  490853889978007552                               @chiyari_ Thanks !!!    en\n",
      "4  490161646678327296                                 ישראל היא הבית שלי    he\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                       ID                                              Tweet  \\\n",
      "11820  484392947555643392  @mk62442 @P0406L เดี๋ยวให้โวลเดอร์มอต์พาตัวมา ^.^   \n",
      "11022  486685688243699713                               Segunda tem aula -.-   \n",
      "11843  487509040751054850                       ลิมิตหรอ กี้ #SbsPopAsiaGOT7   \n",
      "11142  488795219643858945        chego quem desconcentra o duca #ODucaChegou   \n",
      "3044   489696421713833984  @Ferenc2017 Grrrrrrr!!!!! They have some splai...   \n",
      "\n",
      "      Label  \n",
      "11820    th  \n",
      "11022    pt  \n",
      "11843    th  \n",
      "11142    pt  \n",
      "3044     en  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(train_dev_set.head()) #some checks\n",
    "print(type(train_dev_set))\n",
    "print(test_set.head())\n",
    "print(type(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the ID columns, not needed anymore\n",
    "\n",
    "train_dev = train_dev_set.drop(COL_ID, axis=1)\n",
    "test = test_set.drop(COL_ID, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hold on I'm going to brush a horse.\" -Willow 😂😂</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@atsushi022518 \\nあっちゃん、てんねんじゃないよ。天才だよ💫おさとうはまちが...</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Упругое тело… (18+) http://t.co/xpXN8rDqED</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chiyari_ Thanks !!!</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ישראל היא הבית שלי</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Label\n",
       "0   \"Hold on I'm going to brush a horse.\" -Willow 😂😂    en\n",
       "1  @atsushi022518 \\nあっちゃん、てんねんじゃないよ。天才だよ💫おさとうはまちが...    ja\n",
       "2         Упругое тело… (18+) http://t.co/xpXN8rDqED    ru\n",
       "3                               @chiyari_ Thanks !!!    en\n",
       "4                                 ישראל היא הבית שלי    he"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>@mk62442 @P0406L เดี๋ยวให้โวลเดอร์มอต์พาตัวมา ^.^</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11022</th>\n",
       "      <td>Segunda tem aula -.-</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11843</th>\n",
       "      <td>ลิมิตหรอ กี้ #SbsPopAsiaGOT7</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11142</th>\n",
       "      <td>chego quem desconcentra o duca #ODucaChegou</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>@Ferenc2017 Grrrrrrr!!!!! They have some splai...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet Label\n",
       "11820  @mk62442 @P0406L เดี๋ยวให้โวลเดอร์มอต์พาตัวมา ^.^    th\n",
       "11022                               Segunda tem aula -.-    pt\n",
       "11843                       ลิมิตหรอ กี้ #SbsPopAsiaGOT7    th\n",
       "11142        chego quem desconcentra o duca #ODucaChegou    pt\n",
       "3044   @Ferenc2017 Grrrrrrr!!!!! They have some splai...    en"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53469</td>\n",
       "      <td>53469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>53385</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>:(</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8</td>\n",
       "      <td>18764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tweet  Label\n",
       "count   53469  53469\n",
       "unique  53385     77\n",
       "top        :(     en\n",
       "freq        8  18764"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.describe() # descrption of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ar          2295\n",
       "ar             1\n",
       "ar_LATN       12\n",
       "az             1\n",
       "bg             2\n",
       "bn             8\n",
       "bs             4\n",
       "ca            22\n",
       "cs             4\n",
       "cy             1\n",
       "da             7\n",
       "de           171\n",
       "dv             1\n",
       "el            39\n",
       "en         18764\n",
       "es          5978\n",
       "et             2\n",
       "fa            18\n",
       "fi            15\n",
       "fr           954\n",
       "gl             3\n",
       "ha             1\n",
       "he            27\n",
       "hi            16\n",
       "hi-Latn       15\n",
       "hr             5\n",
       "ht             2\n",
       "hu            15\n",
       "hy             2\n",
       "id          3038\n",
       "           ...  \n",
       "nl           182\n",
       "no            11\n",
       "pl            93\n",
       "ps             1\n",
       "ps_LATN        1\n",
       "pt          2888\n",
       "ro            12\n",
       "ru           978\n",
       "si             1\n",
       "sl             2\n",
       "sq             9\n",
       "sr            22\n",
       "su            10\n",
       "sv            54\n",
       "sw             6\n",
       "ta             9\n",
       "ta_LATN        1\n",
       "th           465\n",
       "tl           320\n",
       "tn             1\n",
       "tr           669\n",
       "uk            16\n",
       "und         4835\n",
       "ur             7\n",
       "ur_LATN       12\n",
       "vi            16\n",
       "wo             1\n",
       "xh             1\n",
       "zh-CN         25\n",
       "zh-TW         10\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.groupby(COL_LABEL).size() # more description of the data. See that there are lots of Arabian and English tweets, also quite a few in Spanish and Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dev.Tweet # split the data in Series\n",
    "y_train = train_dev.Label\n",
    "X_test = test.Tweet\n",
    "y_test = test.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#encode the labels. First step means simple encoding, the second makes a series out of the array that was outputted and\n",
    "    #the third step means we output strings again (strings are apparently needed as a format)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_train_series = pd.Series(y_train_encoded)\n",
    "y_train_str = y_train_series.apply(str)\n",
    "\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "y_test_series = pd.Series(y_test_encoded)\n",
    "y_test_str = y_test_series.apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Language classification with linear classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline1 = Pipeline([('tfidf', TfidfVectorizer()), ('clf0', MultinomialNB())]) #first test with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...ue,\n",
       "        vocabulary=None)), ('clf0', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline1.fit(X_train, y_train_str) #using y_train_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['28', '28', '31', ..., '13', '13', '13'], dtype='<U2')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        21\n",
       "1        21\n",
       "2        23\n",
       "3        10\n",
       "4        21\n",
       "5        23\n",
       "6        10\n",
       "7        34\n",
       "8        10\n",
       "9        21\n",
       "10       11\n",
       "11       11\n",
       "12        0\n",
       "13        0\n",
       "14       50\n",
       "15        0\n",
       "16       10\n",
       "17       23\n",
       "18       23\n",
       "19       10\n",
       "20       23\n",
       "21       10\n",
       "22       10\n",
       "23       10\n",
       "24       10\n",
       "25       23\n",
       "26       11\n",
       "27       50\n",
       "28       11\n",
       "29       10\n",
       "         ..\n",
       "13422    23\n",
       "13423    10\n",
       "13424    10\n",
       "13425     0\n",
       "13426    41\n",
       "13427    10\n",
       "13428     0\n",
       "13429    39\n",
       "13430    10\n",
       "13431    23\n",
       "13432    23\n",
       "13433    10\n",
       "13434    23\n",
       "13435    10\n",
       "13436    10\n",
       "13437    10\n",
       "13438    52\n",
       "13439    10\n",
       "13440    10\n",
       "13441    23\n",
       "13442    10\n",
       "13443    10\n",
       "13444    10\n",
       "13445    10\n",
       "13446    41\n",
       "13447    10\n",
       "13448    11\n",
       "13449     0\n",
       "13450     3\n",
       "13451    23\n",
       "Length: 13452, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test_str #doesn't look too right, but it is a very simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first serious pipeline with ngrams and tfidf --> just for test!\n",
    "pipeline_NB01 = Pipeline([\n",
    "    ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf01', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid is fitting the pipeline_NB01\n",
    "param_grid01 = {'clf01__alpha': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'clf01__fit_prior': [True, False]}  #'ngram__ngram_range': [(1, 1), (1, 2), (1, 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  16 out of  16 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('ngram', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
       "        stri...ear_tf=False, use_idf=True)), ('clf01', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'clf01__alpha': [0.2, 0.6, 0.8, 1.0], 'clf01__fit_prior': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This model here seems to work\n",
    "gs_NB01= GridSearchCV(pipeline_NB01, param_grid01, cv=2, n_jobs=2, verbose=1)\n",
    "gs_NB01.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['th', 'pt', 'th', ..., 'pt', 'es', 'tl'], dtype='<U7')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_NB01 = gs_NB01.predict(X_test)\n",
    "y_NB01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11820         th\n",
       "11022         pt\n",
       "11843         th\n",
       "11142         pt\n",
       "3044          en\n",
       "3753          en\n",
       "12143         tr\n",
       "9873          ja\n",
       "7079          fr\n",
       "3522          en\n",
       "2427          en\n",
       "8955          ja\n",
       "11056         pt\n",
       "2266          en\n",
       "10209         ja\n",
       "6013          es\n",
       "2235          en\n",
       "4007          en\n",
       "7556          id\n",
       "4080          en\n",
       "10281         ja\n",
       "9641          ja\n",
       "547      ar_LATN\n",
       "9551          ja\n",
       "5369          en\n",
       "10189         ja\n",
       "550           bg\n",
       "7831          id\n",
       "1347          en\n",
       "10686         ko\n",
       "          ...   \n",
       "8269          ja\n",
       "11124         pt\n",
       "5627          es\n",
       "1532          en\n",
       "2264          en\n",
       "7119          fr\n",
       "6286          es\n",
       "1817          en\n",
       "1497          en\n",
       "2817          en\n",
       "10927         pt\n",
       "6646          es\n",
       "9908          ja\n",
       "4252          en\n",
       "8662          ja\n",
       "9708          ja\n",
       "2150          en\n",
       "6090          es\n",
       "7868          id\n",
       "11810         sv\n",
       "9268          ja\n",
       "9170          ja\n",
       "11331         pt\n",
       "6446          es\n",
       "1287          en\n",
       "2569          en\n",
       "7286          id\n",
       "13226        und\n",
       "6049          es\n",
       "12008         tl\n",
       "Name: Label, Length: 13452, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test #results are quite terrible though \n",
    "# they are actually better than with the avg word length extractor included in the features :D wtf o_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7354296758846268"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_NB01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here we really need to find the best_model out of this data i got. I don't remember how to see it in the matrix, see Tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average word length extractor, inspired  by https://michelleful.github.io/code-blog/2015/06/20/pipelines/)\n",
    "class AverageWordLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes in dataframe, extracts tweet column, outputs average word length\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def average_word_length(self, tweet):\n",
    "        \"\"\"Helper code to compute average word length of a tweet\"\"\"\n",
    "        return np.mean([len(word) for word in tweet.split()])\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        \"\"\"The workhorse of this feature extractor\"\"\"\n",
    "        # the result of the transform needs to be a 2d array a.k.a. dataframe\n",
    "        # https://stackoverflow.com/a/50713209\n",
    "        result = df.apply(self.average_word_length).to_frame()\n",
    "        print(result)\n",
    "        return result\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        \"\"\"Returns `self` unless something different happens in train and test\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read this blog post on how to construct feature unions :) \n",
    "# http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "\n",
    "# the problem was that our previous pipeline went sorta like this:\n",
    "# create n-grams from text (CountVectorizer) -> tfidf from ngrams (TfidfTransformer) -> average length from ngrams (AvgWLExtractor) ummm :) that wouldn't work... we need to compute the average word length from the original data (tweets / strings).\n",
    "# that's why we have to do these two \"pipelines\" separately => now we just compute the avg from the strings like so...\n",
    "\n",
    "pipeline_NB1 = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', Normalizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('nb_clf', MultinomialNB()) # classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     53469\n",
       "unique       77\n",
       "top          en\n",
       "freq      18764\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {'nb_clf__alpha': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'nb_clf__fit_prior': [True, False]}  #'ngram__ngram_range': [(1, 1), (1, 2), (1, 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=2)]: Done  80 out of  80 | elapsed: 12.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Tweet\n",
      "0        3.900000\n",
      "1       25.000000\n",
      "2        9.750000\n",
      "3        6.000000\n",
      "4        3.750000\n",
      "5        5.142857\n",
      "6        4.190476\n",
      "7        4.523810\n",
      "8       10.800000\n",
      "9        6.200000\n",
      "10       5.000000\n",
      "11      13.500000\n",
      "12      16.500000\n",
      "13       9.500000\n",
      "14       3.000000\n",
      "15       3.250000\n",
      "16       7.333333\n",
      "17       4.833333\n",
      "18       8.133333\n",
      "19       5.000000\n",
      "20      37.000000\n",
      "21       5.000000\n",
      "22      12.000000\n",
      "23       4.421053\n",
      "24       6.388889\n",
      "25      15.666667\n",
      "26      12.000000\n",
      "27       6.333333\n",
      "28       4.777778\n",
      "29      11.500000\n",
      "...           ...\n",
      "53439    7.600000\n",
      "53440    4.684211\n",
      "53441   12.000000\n",
      "53442    8.333333\n",
      "53443    5.000000\n",
      "53444    4.000000\n",
      "53445    9.500000\n",
      "53446    9.300000\n",
      "53447   18.285714\n",
      "53448    6.500000\n",
      "53449  140.000000\n",
      "53450   10.500000\n",
      "53451   12.000000\n",
      "53452    4.769231\n",
      "53453    4.166667\n",
      "53454    4.153846\n",
      "53455    4.400000\n",
      "53456    5.619048\n",
      "53457   10.000000\n",
      "53458   22.500000\n",
      "53459    5.809524\n",
      "53460    5.000000\n",
      "53461    4.950000\n",
      "53462    7.600000\n",
      "53463    5.400000\n",
      "53464   23.200000\n",
      "53465    6.500000\n",
      "53466    8.363636\n",
      "53467    4.571429\n",
      "53468   14.111111\n",
      "\n",
      "[53469 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('ngram_tfidf', Pipeline(memory=None,\n",
       "     steps=[('ngram', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max... transformer_weights=None)), ('nb_clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'nb_clf__alpha': [0.2, 0.6, 0.8, 1.0], 'nb_clf__fit_prior': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_NB1= GridSearchCV(pipeline_NB1, param_grid1, cv=10, n_jobs=2, verbose=1)\n",
    "gs_NB1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Tweet\n",
      "11820  11.500000\n",
      "11022   4.250000\n",
      "11843   8.666667\n",
      "11142   6.333333\n",
      "3044    5.461538\n",
      "3753    9.250000\n",
      "12143   8.571429\n",
      "9873   21.000000\n",
      "7079    4.733333\n",
      "3522    5.571429\n",
      "2427    4.750000\n",
      "8955   20.500000\n",
      "11056   5.000000\n",
      "2266    6.210526\n",
      "10209  17.333333\n",
      "6013    4.625000\n",
      "2235    4.142857\n",
      "4007    4.600000\n",
      "7556    6.444444\n",
      "4080    8.800000\n",
      "10281  11.000000\n",
      "9641   14.333333\n",
      "547     7.400000\n",
      "9551   24.666667\n",
      "5369    4.956522\n",
      "10189  41.000000\n",
      "550     9.000000\n",
      "7831    4.421053\n",
      "1347    4.000000\n",
      "10686   3.500000\n",
      "...          ...\n",
      "8269   10.000000\n",
      "11124   4.625000\n",
      "5627    6.066667\n",
      "1532    4.272727\n",
      "2264    6.250000\n",
      "7119    6.142857\n",
      "6286    3.727273\n",
      "1817    9.875000\n",
      "1497    4.153846\n",
      "2817    6.833333\n",
      "10927   3.500000\n",
      "6646    7.666667\n",
      "9908   13.500000\n",
      "4252    7.562500\n",
      "8662    7.500000\n",
      "9708   14.000000\n",
      "2150    7.500000\n",
      "6090    4.352941\n",
      "7868    7.125000\n",
      "11810   4.200000\n",
      "9268    5.000000\n",
      "9170   20.000000\n",
      "11331   5.000000\n",
      "6446   13.000000\n",
      "1287    7.642857\n",
      "2569    5.500000\n",
      "7286    5.400000\n",
      "13226   8.000000\n",
      "6049    3.700000\n",
      "12008   3.750000\n",
      "\n",
      "[13452 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y_NB1 = gs_NB1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nb_clf__alpha</th>\n",
       "      <th>param_nb_clf__fit_prior</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.450784</td>\n",
       "      <td>1.215598</td>\n",
       "      <td>0.985117</td>\n",
       "      <td>0.315522</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.683605</td>\n",
       "      <td>0.678771</td>\n",
       "      <td>0.683159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974581</td>\n",
       "      <td>0.974478</td>\n",
       "      <td>0.974211</td>\n",
       "      <td>0.974008</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>0.973700</td>\n",
       "      <td>0.973579</td>\n",
       "      <td>0.973873</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.846274</td>\n",
       "      <td>1.214728</td>\n",
       "      <td>0.854151</td>\n",
       "      <td>0.102933</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.631120</td>\n",
       "      <td>0.624022</td>\n",
       "      <td>0.623413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873735</td>\n",
       "      <td>0.874138</td>\n",
       "      <td>0.873673</td>\n",
       "      <td>0.873613</td>\n",
       "      <td>0.873499</td>\n",
       "      <td>0.873507</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.872544</td>\n",
       "      <td>0.873699</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.255900</td>\n",
       "      <td>0.982897</td>\n",
       "      <td>1.107839</td>\n",
       "      <td>0.231791</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.632047</td>\n",
       "      <td>0.622160</td>\n",
       "      <td>0.624160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897408</td>\n",
       "      <td>0.897685</td>\n",
       "      <td>0.897882</td>\n",
       "      <td>0.897112</td>\n",
       "      <td>0.897681</td>\n",
       "      <td>0.897542</td>\n",
       "      <td>0.897453</td>\n",
       "      <td>0.896469</td>\n",
       "      <td>0.897525</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.023044</td>\n",
       "      <td>0.746523</td>\n",
       "      <td>0.908931</td>\n",
       "      <td>0.099870</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.610163</td>\n",
       "      <td>0.604097</td>\n",
       "      <td>0.606049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815954</td>\n",
       "      <td>0.814698</td>\n",
       "      <td>0.815694</td>\n",
       "      <td>0.815583</td>\n",
       "      <td>0.814809</td>\n",
       "      <td>0.814758</td>\n",
       "      <td>0.814909</td>\n",
       "      <td>0.814621</td>\n",
       "      <td>0.815145</td>\n",
       "      <td>0.000442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.565887</td>\n",
       "      <td>1.911244</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>0.152788</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': Fa...</td>\n",
       "      <td>0.591246</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.584578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772348</td>\n",
       "      <td>0.772009</td>\n",
       "      <td>0.771950</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.771056</td>\n",
       "      <td>0.771444</td>\n",
       "      <td>0.771332</td>\n",
       "      <td>0.770924</td>\n",
       "      <td>0.771562</td>\n",
       "      <td>0.000422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.472430</td>\n",
       "      <td>0.848787</td>\n",
       "      <td>0.986116</td>\n",
       "      <td>0.202387</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.537463</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.530246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704778</td>\n",
       "      <td>0.704152</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.704072</td>\n",
       "      <td>0.703287</td>\n",
       "      <td>0.703077</td>\n",
       "      <td>0.703307</td>\n",
       "      <td>0.703718</td>\n",
       "      <td>0.703841</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>2.288363</td>\n",
       "      <td>1.149593</td>\n",
       "      <td>0.388676</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.509829</td>\n",
       "      <td>0.504842</td>\n",
       "      <td>0.502614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615676</td>\n",
       "      <td>0.614619</td>\n",
       "      <td>0.615885</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.615282</td>\n",
       "      <td>0.615119</td>\n",
       "      <td>0.613804</td>\n",
       "      <td>0.614683</td>\n",
       "      <td>0.615108</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.163292</td>\n",
       "      <td>1.994885</td>\n",
       "      <td>1.202061</td>\n",
       "      <td>0.620069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': True}</td>\n",
       "      <td>0.489800</td>\n",
       "      <td>0.485661</td>\n",
       "      <td>0.484317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504978</td>\n",
       "      <td>0.503720</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.503678</td>\n",
       "      <td>0.504508</td>\n",
       "      <td>0.504041</td>\n",
       "      <td>0.502181</td>\n",
       "      <td>0.504133</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1      13.450784      1.215598         0.985117        0.315522   \n",
       "3      11.846274      1.214728         0.854151        0.102933   \n",
       "0      13.255900      0.982897         1.107839        0.231791   \n",
       "5      12.023044      0.746523         0.908931        0.099870   \n",
       "7      13.565887      1.911244         0.987051        0.152788   \n",
       "2      12.472430      0.848787         0.986116        0.202387   \n",
       "4      13.750000      2.288363         1.149593        0.388676   \n",
       "6      13.163292      1.994885         1.202061        0.620069   \n",
       "\n",
       "  param_nb_clf__alpha param_nb_clf__fit_prior  \\\n",
       "1                 0.2                   False   \n",
       "3                 0.6                   False   \n",
       "0                 0.2                    True   \n",
       "5                 0.8                   False   \n",
       "7                   1                   False   \n",
       "2                 0.6                    True   \n",
       "4                 0.8                    True   \n",
       "6                   1                    True   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "1  {'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': Fa...           0.683605   \n",
       "3  {'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': Fa...           0.631120   \n",
       "0  {'nb_clf__alpha': 0.2, 'nb_clf__fit_prior': True}           0.632047   \n",
       "5  {'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': Fa...           0.610163   \n",
       "7  {'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': Fa...           0.591246   \n",
       "2  {'nb_clf__alpha': 0.6, 'nb_clf__fit_prior': True}           0.537463   \n",
       "4  {'nb_clf__alpha': 0.8, 'nb_clf__fit_prior': True}           0.509829   \n",
       "6  {'nb_clf__alpha': 1.0, 'nb_clf__fit_prior': True}           0.489800   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  split2_train_score  \\\n",
       "1           0.678771           0.683159  ...            0.974581   \n",
       "3           0.624022           0.623413  ...            0.873735   \n",
       "0           0.622160           0.624160  ...            0.897408   \n",
       "5           0.604097           0.606049  ...            0.815954   \n",
       "7           0.586592           0.584578  ...            0.772348   \n",
       "2           0.533333           0.530246  ...            0.704778   \n",
       "4           0.504842           0.502614  ...            0.615676   \n",
       "6           0.485661           0.484317  ...            0.504978   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "1            0.974478            0.974211            0.974008   \n",
       "3            0.874138            0.873673            0.873613   \n",
       "0            0.897685            0.897882            0.897112   \n",
       "5            0.814698            0.815694            0.815583   \n",
       "7            0.772009            0.771950            0.771369   \n",
       "2            0.704152            0.704017            0.704072   \n",
       "4            0.614619            0.615885            0.615188   \n",
       "6            0.503720            0.504167            0.503678   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "1            0.974218            0.973700            0.973579   \n",
       "3            0.873499            0.873507            0.873214   \n",
       "0            0.897681            0.897542            0.897453   \n",
       "5            0.814809            0.814758            0.814909   \n",
       "7            0.771056            0.771444            0.771332   \n",
       "2            0.703287            0.703077            0.703307   \n",
       "4            0.615282            0.615119            0.613804   \n",
       "6            0.504508            0.504041            0.502181   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  \n",
       "1            0.973873          0.974189         0.000385  \n",
       "3            0.872544          0.873699         0.000599  \n",
       "0            0.896469          0.897525         0.000492  \n",
       "5            0.814621          0.815145         0.000442  \n",
       "7            0.770924          0.771562         0.000422  \n",
       "2            0.703718          0.703841         0.000480  \n",
       "4            0.614683          0.615108         0.000572  \n",
       "6            0.504133          0.503966         0.000693  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result = pd.DataFrame.from_dict(gs_NB1.cv_results_)\n",
    "grid_result.sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best model is with an alpha of 0.2 and a fit_prior: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Tweet\n",
      "0        3.900000\n",
      "1       25.000000\n",
      "2        9.750000\n",
      "3        6.000000\n",
      "4        3.750000\n",
      "5        5.142857\n",
      "6        4.190476\n",
      "7        4.523810\n",
      "8       10.800000\n",
      "9        6.200000\n",
      "10       5.000000\n",
      "11      13.500000\n",
      "12      16.500000\n",
      "13       9.500000\n",
      "14       3.000000\n",
      "15       3.250000\n",
      "16       7.333333\n",
      "17       4.833333\n",
      "18       8.133333\n",
      "19       5.000000\n",
      "20      37.000000\n",
      "21       5.000000\n",
      "22      12.000000\n",
      "23       4.421053\n",
      "24       6.388889\n",
      "25      15.666667\n",
      "26      12.000000\n",
      "27       6.333333\n",
      "28       4.777778\n",
      "29      11.500000\n",
      "...           ...\n",
      "53439    7.600000\n",
      "53440    4.684211\n",
      "53441   12.000000\n",
      "53442    8.333333\n",
      "53443    5.000000\n",
      "53444    4.000000\n",
      "53445    9.500000\n",
      "53446    9.300000\n",
      "53447   18.285714\n",
      "53448    6.500000\n",
      "53449  140.000000\n",
      "53450   10.500000\n",
      "53451   12.000000\n",
      "53452    4.769231\n",
      "53453    4.166667\n",
      "53454    4.153846\n",
      "53455    4.400000\n",
      "53456    5.619048\n",
      "53457   10.000000\n",
      "53458   22.500000\n",
      "53459    5.809524\n",
      "53460    5.000000\n",
      "53461    4.950000\n",
      "53462    7.600000\n",
      "53463    5.400000\n",
      "53464   23.200000\n",
      "53465    6.500000\n",
      "53466    8.363636\n",
      "53467    4.571429\n",
      "53468   14.111111\n",
      "\n",
      "[53469 rows x 1 columns]\n",
      "           Tweet\n",
      "11820  11.500000\n",
      "11022   4.250000\n",
      "11843   8.666667\n",
      "11142   6.333333\n",
      "3044    5.461538\n",
      "3753    9.250000\n",
      "12143   8.571429\n",
      "9873   21.000000\n",
      "7079    4.733333\n",
      "3522    5.571429\n",
      "2427    4.750000\n",
      "8955   20.500000\n",
      "11056   5.000000\n",
      "2266    6.210526\n",
      "10209  17.333333\n",
      "6013    4.625000\n",
      "2235    4.142857\n",
      "4007    4.600000\n",
      "7556    6.444444\n",
      "4080    8.800000\n",
      "10281  11.000000\n",
      "9641   14.333333\n",
      "547     7.400000\n",
      "9551   24.666667\n",
      "5369    4.956522\n",
      "10189  41.000000\n",
      "550     9.000000\n",
      "7831    4.421053\n",
      "1347    4.000000\n",
      "10686   3.500000\n",
      "...          ...\n",
      "8269   10.000000\n",
      "11124   4.625000\n",
      "5627    6.066667\n",
      "1532    4.272727\n",
      "2264    6.250000\n",
      "7119    6.142857\n",
      "6286    3.727273\n",
      "1817    9.875000\n",
      "1497    4.153846\n",
      "2817    6.833333\n",
      "10927   3.500000\n",
      "6646    7.666667\n",
      "9908   13.500000\n",
      "4252    7.562500\n",
      "8662    7.500000\n",
      "9708   14.000000\n",
      "2150    7.500000\n",
      "6090    4.352941\n",
      "7868    7.125000\n",
      "11810   4.200000\n",
      "9268    5.000000\n",
      "9170   20.000000\n",
      "11331   5.000000\n",
      "6446   13.000000\n",
      "1287    7.642857\n",
      "2569    5.500000\n",
      "7286    5.400000\n",
      "13226   8.000000\n",
      "6049    3.700000\n",
      "12008   3.750000\n",
      "\n",
      "[13452 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "best_model = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', Normalizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('nb_clf', MultinomialNB(alpha=0.2, fit_prior=False)) # classifier\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "best_model_prediction = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885964912280702"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, best_model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885964912280702"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_NB1)\n",
    "# not rly sure why the accuracy is lower than NB01, kinda confused bout this :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debora/Envs/nlppython/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  16 out of  16 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7331251858459709"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test without avg but with a nested FeatureUnion with 1 feature (pipeline)\n",
    "# This should have the same accuracy as NB01, and it does... which implies that the pipeline/featureunion thing is correct. I'd say we have to look into hyperparams to fix the accuracy.\n",
    "pipeline_NB2 = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('nb_clf', MultinomialNB()) # classifier\n",
    "])\n",
    "\n",
    "gs_NB2= GridSearchCV(pipeline_NB2, param_grid1, cv=10, n_jobs=2, verbose=1) # same param_grid as NB1\n",
    "gs_NB2.fit(X_train, y_train)\n",
    "y_NB2 = gs_NB2.predict(X_test)\n",
    "accuracy_score(y_test, y_NB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a try with SGD, same features!\n",
    "pipeline_SGD = Pipeline([\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer()), \n",
    "        ])),\n",
    "        ('ave', AverageWordLengthExtractor())\n",
    "    ])),\n",
    "    ('SGD_clf', SGDClassifier())# classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_SGD = {'SGD_clf__loss': ['hinge', 'log'],\n",
    "                  'SGD_clf__penalty': ['none', 'l1', 'l2'],\n",
    "                  'SGD_clf__max_iter': [50, 100, 500, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_SGD = GridSearchCV(pipeline_SGD, grid_param_SGD, cv=10, n_jobs=2, verbose=1)\n",
    "gs_SGD.fit(X_train, y_train)\n",
    "##NOTE: it crashed^s at the same point: could not convert string to float: 'ញាំថ្នាំផ្តាសសាយខ្លាំពេកឡើងគេញលែងចង់ចង់ក្រោកហើយ....'\n",
    "#Maybe some problem with the encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SGD = gs_SGD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609277430865299"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP_CLF = 'MLP_clf'\n",
    "\n",
    "pipeline_MLP = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', Normalizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    (MLP_CLF, MLPClassifier()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_MLP = { MLP_CLF + '__hidden_layer_sizes': [(4, 3), (5, 3)],\n",
    "                   MLP_CLF + '__activation': ['tanh', 'relu'],\n",
    "                   MLP_CLF + '__solver': ['sgd', 'adam'],\n",
    "                   MLP_CLF + '__max_iter': [50],\n",
    "                   MLP_CLF + '__momentum': [0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "gs_MLP = GridSearchCV(pipeline_MLP, grid_param_MLP, cv=10, n_jobs=2, verbose=1)\n",
    "gs_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
