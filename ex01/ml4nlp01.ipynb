{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# File paths\n",
    "DATA_FP = \"./data/\" # Data file path\n",
    "TWEETS_FP = DATA_FP + \"tweets.json\"\n",
    "TRAIN_DEV_FP = DATA_FP + \"labels-train+dev.tsv\"\n",
    "TEST_FP = DATA_FP + \"labels-test.tsv\"\n",
    "\n",
    "# Column names\n",
    "COL_ID = 'ID'\n",
    "COL_TWEET = 'Tweet'\n",
    "COL_LABEL = 'Label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data\n",
    "\n",
    "## Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the first file (Tweets)\n",
    "tweets = []\n",
    "with open(TWEETS_FP, 'r') as tweets_fh:  # Tweets file handle\n",
    "    for line in tweets_fh:   # put each line in a list of lines\n",
    "        j_content = json.loads(line)\n",
    "        tweets.append(j_content)\n",
    "\n",
    "tweets = pd.DataFrame(tweets, columns=[COL_ID, COL_TWEET])  # make a dataframe out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with both label documents\n",
    "\n",
    "train_dev_labels = pd.read_csv(TRAIN_DEV_FP, sep='\\t', header=None, names=[COL_LABEL, COL_ID])\n",
    "test_labels = pd.read_csv(TEST_FP, sep='\\t', header=None, names=[COL_LABEL, COL_ID])\n",
    "\n",
    "# deal with class imbalance in the train set\n",
    "lang_occurence = train.groupby(COL_LABEL).size()\n",
    "MIN_NR_OCCURENCES = 5  # minimum number of instances that we require to be present in the training set for a given language to be included in fitting of the model\n",
    "balanced_languages = lang_occurence.where(lambda x: x >= MIN_NR_OCCURENCES).dropna().index.values\n",
    "balanced_labels = train_dev_labels.Label.isin(balanced_languages)\n",
    "\n",
    "# Option 1 - replace rows that are labelled with an imbalanced language\n",
    "train_dev_labels.loc[~balanced_labels, 'Label'] = 'unknown'  # ~ is the element-wise logical not\n",
    "\n",
    "# Option 2 - keep the rows that are labelled with a balanced language\n",
    "# train_dev_labels = train_dev_labels[balanced_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[COL_ID] = tweets[COL_ID].astype(int) # to allow for merge, need the same type\n",
    "\n",
    "train_dev_data = pd.merge(tweets, train_dev_labels, on=COL_ID) # merge by ID\n",
    "test_data = pd.merge(tweets, test_labels, on=COL_ID) # merge by ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_n_shuffle(data):\n",
    "    data_no_na = data.dropna().copy()\n",
    "    return data_no_na.sample(frac=1)\n",
    "\n",
    "train_dev_data_prepared = drop_n_shuffle(train_dev_data).reset_index(drop = True)\n",
    "train_set = train_dev_data_prepared.sample(frac=0.9, random_state=0) # take 90% of the data, reshuffle\n",
    "test_set = drop_n_shuffle(test_data)\n",
    "dev_set = train_dev_data_prepared.drop(train_set.index) # take 10% that remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the ID columns, not needed anymore\n",
    "\n",
    "train = train_set.drop(COL_ID, axis=1)\n",
    "dev = dev_set.drop(COL_ID, axis=1)\n",
    "test = test_set.drop(COL_ID, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.Tweet \n",
    "y_train = train.Label\n",
    "X_dev = dev.Tweet\n",
    "y_dev = dev.Label\n",
    "X_test = test.Tweet\n",
    "y_test = test.Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Language classification with linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average word length extractor, inspired  by https://michelleful.github.io/code-blog/2015/06/20/pipelines/)\n",
    "class AverageWordLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes in dataframe, extracts tweet column, outputs average word length\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def average_word_length(self, tweet):\n",
    "        \"\"\"Helper code to compute average word length of a tweet\"\"\"\n",
    "        return np.mean([len(word) for word in tweet.split()])\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        \"\"\"The workhorse of this feature extractor\"\"\"\n",
    "        # the result of the transform needs to be a 2d array a.k.a. dataframe\n",
    "        # https://stackoverflow.com/a/50713209\n",
    "        result = df.apply(self.average_word_length).to_frame()\n",
    "        return result\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        \"\"\"Returns `self` unless something different happens in train and test\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_NB = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', MinMaxScaler())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('nb_clf', MultinomialNB()) # classifier\n",
    "])\n",
    "\n",
    "param_grid1 = {'nb_clf__alpha': [0.1, 0.2, 0.3, 0.6],\n",
    "                'nb_clf__fit_prior': [False],\n",
    "                'features__ngram_tfidf__ngram__ngram_range': [(1, 2), (1, 4)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   22.8s\n"
     ]
    }
   ],
   "source": [
    "gs_NB = GridSearchCV(pipeline_NB, param_grid1, cv=4, n_jobs=-1, verbose=10)\n",
    "gs_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_NB = gs_NB.predict(X_dev)\n",
    "accuracy_score(y_dev, y_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_features__ngram_tfidf__ngram__ngram_range</th>\n",
       "      <th>param_nb_clf__alpha</th>\n",
       "      <th>param_nb_clf__fit_prior</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.844728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.831179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.826337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.825776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.821973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.820290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.816176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.675346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.606646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.604131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.590063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.582603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.565209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score param_features__ngram_tfidf__ngram__ngram_range  \\\n",
       "1                 1                                          (1, 2)   \n",
       "9                 2                                          (1, 4)   \n",
       "3                 3                                          (1, 2)   \n",
       "5                 4                                          (1, 2)   \n",
       "11                5                                          (1, 4)   \n",
       "7                 6                                          (1, 2)   \n",
       "13                7                                          (1, 4)   \n",
       "15                8                                          (1, 4)   \n",
       "0                 9                                          (1, 2)   \n",
       "8                10                                          (1, 4)   \n",
       "2                11                                          (1, 2)   \n",
       "4                12                                          (1, 2)   \n",
       "10               13                                          (1, 4)   \n",
       "6                14                                          (1, 2)   \n",
       "12               15                                          (1, 4)   \n",
       "14               16                                          (1, 4)   \n",
       "\n",
       "   param_nb_clf__alpha param_nb_clf__fit_prior  mean_test_score  \n",
       "1                  0.2                   False         0.844728  \n",
       "9                  0.2                   False         0.840946  \n",
       "3                  0.6                   False         0.831179  \n",
       "5                  0.8                   False         0.826337  \n",
       "11                 0.6                   False         0.825776  \n",
       "7                    1                   False         0.821973  \n",
       "13                 0.8                   False         0.820290  \n",
       "15                   1                   False         0.816176  \n",
       "0                  0.2                    True         0.675346  \n",
       "8                  0.2                    True         0.660363  \n",
       "2                  0.6                    True         0.625223  \n",
       "4                  0.8                    True         0.606646  \n",
       "10                 0.6                    True         0.604131  \n",
       "6                    1                    True         0.590063  \n",
       "12                 0.8                    True         0.582603  \n",
       "14                   1                    True         0.565209  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame.from_dict(gs_NB1.cv_results_)\n",
    "res.sort_values(by='rank_test_score')[['rank_test_score', 'param_features__ngram_tfidf__ngram__ngram_range', 'param_nb_clf__alpha', 'param_nb_clf__fit_prior', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_SGD = Pipeline([\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer()), \n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', MinMaxScaler())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('SGD_clf', SGDClassifier())# classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_SGD = {'SGD_clf__loss': ['hinge', 'log'],\n",
    "                  'SGD_clf__penalty': ['none', 'l1', 'l2'],\n",
    "                  'SGD_clf__max_iter': [100, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('feats',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('ngram_tfidf',\n",
       "                                                                        Pipeline(memory=None,\n",
       "                                                                                 steps=[('ngram',\n",
       "                                                                                         CountVectorizer(analyzer='word',\n",
       "                                                                                                         binary=False,\n",
       "                                                                                                         decode_error='strict',\n",
       "                                                                                                         dtype=<class 'numpy.int64'>,\n",
       "                                                                                                         encoding='utf-8',\n",
       "                                                                                                         input='content',\n",
       "                                                                                                         lowercase=True,\n",
       "                                                                                                         max_df=1.0,\n",
       "                                                                                                         max_f...\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=None,\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'SGD_clf__loss': ['hinge', 'log'],\n",
       "                         'SGD_clf__max_iter': [100, 200],\n",
       "                         'SGD_clf__penalty': ['none', 'l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SGD = GridSearchCV(pipeline_SGD, grid_param_SGD, cv=4, n_jobs=-1, verbose=10)\n",
    "gs_SGD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8447727697774453"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_SGD = gs_SGD.predict(X_dev)\n",
    "accuracy_score(y_dev, y_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_SGD_clf__loss</th>\n",
       "      <th>param_SGD_clf__max_iter</th>\n",
       "      <th>param_SGD_clf__penalty</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>200</td>\n",
       "      <td>none</td>\n",
       "      <td>0.835709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>none</td>\n",
       "      <td>0.835564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.794917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>hinge</td>\n",
       "      <td>200</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.792216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>log</td>\n",
       "      <td>100</td>\n",
       "      <td>none</td>\n",
       "      <td>0.789348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>log</td>\n",
       "      <td>200</td>\n",
       "      <td>none</td>\n",
       "      <td>0.789265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>hinge</td>\n",
       "      <td>200</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.724596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.717219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>log</td>\n",
       "      <td>200</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.687170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>log</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.686277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>log</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.673767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>log</td>\n",
       "      <td>200</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.673289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score param_SGD_clf__loss param_SGD_clf__max_iter  \\\n",
       "3                 1               hinge                     200   \n",
       "0                 2               hinge                     100   \n",
       "2                 3               hinge                     100   \n",
       "5                 4               hinge                     200   \n",
       "6                 5                 log                     100   \n",
       "9                 6                 log                     200   \n",
       "4                 7               hinge                     200   \n",
       "1                 8               hinge                     100   \n",
       "10                9                 log                     200   \n",
       "7                10                 log                     100   \n",
       "8                11                 log                     100   \n",
       "11               12                 log                     200   \n",
       "\n",
       "   param_SGD_clf__penalty  mean_test_score  \n",
       "3                    none         0.835709  \n",
       "0                    none         0.835564  \n",
       "2                      l2         0.794917  \n",
       "5                      l2         0.792216  \n",
       "6                    none         0.789348  \n",
       "9                    none         0.789265  \n",
       "4                      l1         0.724596  \n",
       "1                      l1         0.717219  \n",
       "10                     l1         0.687170  \n",
       "7                      l1         0.686277  \n",
       "8                      l2         0.673767  \n",
       "11                     l2         0.673289  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame.from_dict(gs_SGD.cv_results_)\n",
    "res.sort_values(by='rank_test_score')[['rank_test_score', 'param_SGD_clf__loss', 'param_SGD_clf__max_iter', 'param_SGD_clf__penalty', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_CLF = 'MLP_clf'\n",
    "\n",
    "pipeline_MLP = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # first feature\n",
    "        ('ngram_tfidf', Pipeline([\n",
    "            ('ngram', CountVectorizer(ngram_range=(1, 4), analyzer='word')),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        # second feature\n",
    "        ('ave_scaled', Pipeline([\n",
    "            ('ave', AverageWordLengthExtractor()),\n",
    "            ('scale', MinMaxScaler())\n",
    "        ]))\n",
    "    ])),\n",
    "    (MLP_CLF, MLPClassifier()) \n",
    "])\n",
    "\n",
    "grid_param_MLP = { MLP_CLF + '__hidden_layer_sizes': [(25,)],\n",
    "                   MLP_CLF + '__activation': ['relu'],\n",
    "                   MLP_CLF + '__solver': ['adam'],\n",
    "                   MLP_CLF + '__max_iter': [20],\n",
    "                   MLP_CLF + '__momentum': [0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 96.2min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed: 96.2min remaining: 96.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 96.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 96.5min finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('features',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('ngram_tfidf',\n",
       "                                                                        Pipeline(memory=None,\n",
       "                                                                                 steps=[('ngram',\n",
       "                                                                                         CountVectorizer(analyzer='word',\n",
       "                                                                                                         binary=False,\n",
       "                                                                                                         decode_error='strict',\n",
       "                                                                                                         dtype=<class 'numpy.int64'>,\n",
       "                                                                                                         encoding='utf-8',\n",
       "                                                                                                         input='content',\n",
       "                                                                                                         lowercase=True,\n",
       "                                                                                                         max_df=1.0,\n",
       "                                                                                                         ma...\n",
       "                                                      solver='adam', tol=0.0001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'MLP_clf__activation': ['relu'],\n",
       "                         'MLP_clf__hidden_layer_sizes': [(25,)],\n",
       "                         'MLP_clf__max_iter': [20], 'MLP_clf__momentum': [0.9],\n",
       "                         'MLP_clf__solver': ['adam']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_MLP = GridSearchCV(pipeline_MLP, grid_param_MLP, n_jobs=-1, verbose=10)\n",
    "gs_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mlp = gs_MLP.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.814101365251543"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_dev, y_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_MLP_clf__activation</th>\n",
       "      <th>param_MLP_clf__hidden_layer_sizes</th>\n",
       "      <th>param_MLP_clf__max_iter</th>\n",
       "      <th>param_MLP_clf__momentum</th>\n",
       "      <th>param_MLP_clf__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277.731456</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>1.302234</td>\n",
       "      <td>0.010232</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...</td>\n",
       "      <td>0.350828</td>\n",
       "      <td>0.351429</td>\n",
       "      <td>0.351128</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373.916279</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>1.333323</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...</td>\n",
       "      <td>0.648922</td>\n",
       "      <td>0.673115</td>\n",
       "      <td>0.661007</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>357.605429</td>\n",
       "      <td>0.338305</td>\n",
       "      <td>1.623696</td>\n",
       "      <td>0.034237</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...</td>\n",
       "      <td>0.350828</td>\n",
       "      <td>0.351429</td>\n",
       "      <td>0.351128</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>474.193237</td>\n",
       "      <td>0.280791</td>\n",
       "      <td>1.402589</td>\n",
       "      <td>0.120243</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...</td>\n",
       "      <td>0.597974</td>\n",
       "      <td>0.627356</td>\n",
       "      <td>0.612651</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264.683728</td>\n",
       "      <td>0.129365</td>\n",
       "      <td>1.416832</td>\n",
       "      <td>0.077422</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'MLP_clf__activation': 'relu', 'MLP_clf__hidd...</td>\n",
       "      <td>0.350828</td>\n",
       "      <td>0.351429</td>\n",
       "      <td>0.351128</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>353.529966</td>\n",
       "      <td>0.124757</td>\n",
       "      <td>1.388335</td>\n",
       "      <td>0.100204</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'MLP_clf__activation': 'relu', 'MLP_clf__hidd...</td>\n",
       "      <td>0.668937</td>\n",
       "      <td>0.740422</td>\n",
       "      <td>0.704647</td>\n",
       "      <td>0.035743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>340.663349</td>\n",
       "      <td>0.152085</td>\n",
       "      <td>1.470408</td>\n",
       "      <td>0.085144</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'MLP_clf__activation': 'relu', 'MLP_clf__hidd...</td>\n",
       "      <td>0.350828</td>\n",
       "      <td>0.351429</td>\n",
       "      <td>0.351128</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>547.581941</td>\n",
       "      <td>0.392927</td>\n",
       "      <td>1.741871</td>\n",
       "      <td>0.329597</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'MLP_clf__activation': 'relu', 'MLP_clf__hidd...</td>\n",
       "      <td>0.600507</td>\n",
       "      <td>0.705021</td>\n",
       "      <td>0.652716</td>\n",
       "      <td>0.052257</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     277.731456      0.010334         1.302234        0.010232   \n",
       "1     373.916279      0.055184         1.333323        0.013040   \n",
       "2     357.605429      0.338305         1.623696        0.034237   \n",
       "3     474.193237      0.280791         1.402589        0.120243   \n",
       "4     264.683728      0.129365         1.416832        0.077422   \n",
       "5     353.529966      0.124757         1.388335        0.100204   \n",
       "6     340.663349      0.152085         1.470408        0.085144   \n",
       "7     547.581941      0.392927         1.741871        0.329597   \n",
       "\n",
       "  param_MLP_clf__activation param_MLP_clf__hidden_layer_sizes  \\\n",
       "0                      tanh                            (4, 3)   \n",
       "1                      tanh                            (4, 3)   \n",
       "2                      tanh                            (5, 3)   \n",
       "3                      tanh                            (5, 3)   \n",
       "4                      relu                            (4, 3)   \n",
       "5                      relu                            (4, 3)   \n",
       "6                      relu                            (5, 3)   \n",
       "7                      relu                            (5, 3)   \n",
       "\n",
       "  param_MLP_clf__max_iter param_MLP_clf__momentum param_MLP_clf__solver  \\\n",
       "0                      50                     0.9                   sgd   \n",
       "1                      50                     0.9                  adam   \n",
       "2                      50                     0.9                   sgd   \n",
       "3                      50                     0.9                  adam   \n",
       "4                      50                     0.9                   sgd   \n",
       "5                      50                     0.9                  adam   \n",
       "6                      50                     0.9                   sgd   \n",
       "7                      50                     0.9                  adam   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...           0.350828   \n",
       "1  {'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...           0.648922   \n",
       "2  {'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...           0.350828   \n",
       "3  {'MLP_clf__activation': 'tanh', 'MLP_clf__hidd...           0.597974   \n",
       "4  {'MLP_clf__activation': 'relu', 'MLP_clf__hidd...           0.350828   \n",
       "5  {'MLP_clf__activation': 'relu', 'MLP_clf__hidd...           0.668937   \n",
       "6  {'MLP_clf__activation': 'relu', 'MLP_clf__hidd...           0.350828   \n",
       "7  {'MLP_clf__activation': 'relu', 'MLP_clf__hidd...           0.600507   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.351429         0.351128        0.000300                5  \n",
       "1           0.673115         0.661007        0.012096                2  \n",
       "2           0.351429         0.351128        0.000300                5  \n",
       "3           0.627356         0.612651        0.014691                4  \n",
       "4           0.351429         0.351128        0.000300                5  \n",
       "5           0.740422         0.704647        0.035743                1  \n",
       "6           0.351429         0.351128        0.000300                5  \n",
       "7           0.705021         0.652716        0.052257                3  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame.from_dict(gs_MLP.cv_results_)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
