{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DQTQQGF_TMcD",
    "outputId": "860d0c42-0384-4202-ef8b-b8370ef7d46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c085470>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* https://iksinc.online/tag/continuous-bag-of-words-cbow/\n",
    "* http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf\n",
    "* https://stackoverflow.com/questions/48479915/what-is-the-preferred-ratio-between-the-vocabulary-size-and-embedding-dimension\n",
    "* https://github.com/FraLotito/pytorch-continuous-bag-of-words/blob/master/cbow.py\n",
    "* https://stackoverflow.com/questions/50792316/what-does-1-mean-in-pytorch-view\n",
    "* https://www.tensorflow.org/tutorials/text/word_embeddings\n",
    "* https://pytorch.org/docs/stable/nn.html\n",
    "* https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "* https://github.com/ChristophAlt/embedding_vectorizer/blob/master/embedding_vectorizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "class Vocabulary():\n",
    "    def __init__(self, filepath):\n",
    "        super(Vocabulary, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.tokens = self.nltk_tokenize()\n",
    "        self.tok_to_ids, self.ids_to_tok = self.make_dicts()\n",
    "        self.nr_unique_tokens = len(self.vocabulary_set())\n",
    "    \n",
    "    def readfile(self):\n",
    "        \"\"\"this function opens the file and returns the text in a string\"\"\"\n",
    "        file = open(self.filepath)\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text\n",
    "    \n",
    "    def nltk_tokenize(self):\n",
    "        \"\"\"this function tokenizes the text and returns a list of tokens as strings\"\"\"\n",
    "        text = self.readfile()\n",
    "        tokens = nltk.tokenize.word_tokenize(text)\n",
    "        return tokens\n",
    "    \n",
    "    def vocabulary_set(self):\n",
    "        \"\"\"this function returns a list of unique tokens\"\"\"\n",
    "        return(list(set(self.tokens)))\n",
    "    \n",
    "    def make_dicts(self):\n",
    "        unique_tokens = self.vocabulary_set()\n",
    "        tok_to_ix = {}\n",
    "        ix_to_tok = {}\n",
    "        for i in range(len(unique_tokens)):\n",
    "            tok_to_ix.update({unique_tokens[i]: i})\n",
    "            ix_to_tok.update({i: unique_tokens[i]})\n",
    "        return tok_to_ix, ix_to_tok\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocab = vocabulary\n",
    "    \n",
    "    def vectorize(self, context_words):\n",
    "        context_ids = [self.vocab.tok_to_ids[w] for w in context_words]\n",
    "        return torch.tensor(context_ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'test_corpus.txt'\n",
    "test_vocab = Vocabulary(filepath)\n",
    "vectorizer = Vectorizer(test_vocab)\n",
    "\n",
    "# Size of the context windows, 2 and 5 are supposed to be used in ex02...\n",
    "# range \\in [2, 1/2 * document_length - 1]\n",
    "CONTEXT_SIZE = 2\n",
    "\n",
    "# let's stick with this notation for now ;)\n",
    "CONTEXT_WINDOW_SIZE = CONTEXT_SIZE * 2\n",
    "\n",
    "\n",
    "# Data creation - get context around the target word\n",
    "data = []\n",
    "tokens = test_vocab.tokens\n",
    "for i in range(CONTEXT_SIZE, len(tokens) - CONTEXT_SIZE):\n",
    "    # Context before w_i\n",
    "    context_before_w = tokens[i - CONTEXT_SIZE: i]\n",
    "    \n",
    "    # Context after w_i\n",
    "    context_after_w = tokens[i + 1: i + CONTEXT_SIZE + 1]\n",
    "    \n",
    "    # Put them together\n",
    "    context_window = context_before_w + context_after_w\n",
    "    \n",
    "    # Target = w_i\n",
    "    target = tokens[i]\n",
    "    \n",
    "    # Append in the correct format\n",
    "    data.append((context_window, target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_window_size, nr_hidden_neurons=128):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.context_window_size = context_window_size\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # note: this probably doesn't deal with 'UNK' words\n",
    "        self.linear1 = nn.Linear(embedding_dim, nr_hidden_neurons)  \n",
    "        \n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(nr_hidden_neurons, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # shape = (WINDOW_SIZE, EMBEDDING_DIM) -> (EMBEDDING_DIM)\n",
    "        embeds = sum(self.embeddings(inputs))\n",
    "\n",
    "        # shape = (1, EMBEDDING_DIM)\n",
    "        # -1 param in view() ... \"the actual value for this dimension will be inferred so that the number of elements in the view matches the original number of elements.\"\n",
    "        embeds_2D = embeds.view(1, -1)\n",
    "        \n",
    "        # finally compute the hidden layer weighted sum (a.k.a. output before using the activation function)\n",
    "        # ... and don't forget to divide by the number of input vectors\n",
    "        h =  self.linear1(embeds_2D) / self.context_window_size\n",
    "        \n",
    "        # output of the hidden layer\n",
    "        out =  F.relu(h) \n",
    "         \n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.6298, -0.9274,  0.5451],\n",
      "        [ 0.0663, -0.4370,  0.7626,  ...,  1.1899,  0.8165, -0.9135],\n",
      "        [ 1.3851, -0.8138, -0.9276,  ...,  0.6419,  0.4730, -0.4286],\n",
      "        ...,\n",
      "        [-2.6061,  1.6771,  0.6073,  ...,  0.2068,  1.5356,  2.0230],\n",
      "        [-0.0422,  0.5282,  1.4127,  ...,  1.0123,  1.0741, -0.8674],\n",
      "        [-1.0755, -1.6713,  1.0103,  ..., -0.1815, -0.9565,  0.5544]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2136.317570090294, 1848.2236312031746, 1537.0721579790115, 1108.7981663995888, 621.7661946658045, 220.31571922061994, 127.73664233939053, 53.939336030788574, 21.397852832289345, 14.278862434849088, 11.086158733673528, 9.568845190579395, 8.552210102504318, 7.794820925921954, 7.230557759313228, 6.7624459104945345, 6.367696825967187, 6.053731640840169, 5.767266283014806, 5.516324089526506, 5.3117749457918535, 5.126185958738915, 4.946587336271023, 4.805358973127682, 4.661977805815354, 4.531068837706357, 4.426681671878782, 4.317843586064214, 4.218298862960751, 4.134484423576964, 4.049092979382863, 3.9688225721635035, 3.9032739591835934, 3.8348483784062637, 3.772967166161493, 3.7189080517651973, 3.6570920978462027, 3.602395747122273, 3.5538184786980764, 3.508177672023294, 3.4608298431137428, 3.419683747260706, 3.3781110732904835, 3.3470492774174545, 3.3048332985906654, 3.27129527026932, 3.2349509448611116, 3.2020637595958306, 3.1716711766819117, 3.1476067342280203, 3.1159877296829563, 3.089516374002187, 3.060402012302575, 3.0363376346692803, 3.011015646667829, 2.99144434542427, 2.966596738265025, 2.942460056423215, 2.921255954927574, 2.905267444872834, 2.882490733822806, 2.865282837697805, 2.8436837304177516, 2.826279844983901, 2.809240561256729, 2.791281460356686, 2.774207945697299, 2.76305266689252, 2.7440335910395106, 2.736902290500325, 2.7154669523141592, 2.699590290005176, 2.6848408642089225, 2.6715615074689367, 2.658002677639047, 2.647594074463882, 2.633544220291583, 2.6235077123873225, 2.6091235536713384, 2.5979166364057846, 2.592813157069827, 2.5756666936084684, 2.563909435677374, 2.5542353782583405, 2.5435187241336052, 2.5346444002451562, 2.5234812909938, 2.512988876900522, 2.503498544752688, 2.494740745226295, 2.4911739712414374, 2.4772236592124273, 2.4684600401322996, 2.4596144739533656, 2.4513285923720787, 2.4439150642919003, 2.434735571385204, 2.426753272002202, 2.4192274382957066, 2.412104753205199]\n",
      "Parameter containing:\n",
      "tensor([[-1.5403, -0.7449, -0.6331,  ..., -0.6546, -0.9677,  0.5400],\n",
      "        [ 0.0541, -0.4999,  0.7570,  ...,  1.1749,  0.8489, -0.9413],\n",
      "        [ 1.4160, -0.8161, -0.9651,  ...,  0.6631,  0.4312, -0.3760],\n",
      "        ...,\n",
      "        [-2.5474,  1.6856,  0.6054,  ...,  0.1749,  1.5633,  2.0433],\n",
      "        [-0.0051,  0.5326,  1.5840,  ...,  0.9545,  1.2243, -0.9725],\n",
      "        [-1.0945, -1.7268,  1.0097,  ..., -0.1591, -0.9996,  0.5261]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS = 100\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss() # negative log likelihood loss\n",
    "model = CBOW(test_vocab.nr_unique_tokens, EMBEDDING_DIM, CONTEXT_WINDOW_SIZE)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(model.embeddings.weight)\n",
    "\n",
    "for epoch in tqdm(range(NUM_ITERATIONS)):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        # Step1. Create input vector \n",
    "        context_vectors = vectorizer.vectorize(context)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_vectors)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        target = torch.tensor(vectorizer.vocab.tok_to_ids[target], dtype=torch.long).view(1)\n",
    "        loss = loss_function(log_probs, target)\n",
    "        \n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(losses)\n",
    "print(model.embeddings.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of word_embeddings_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
