{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DQTQQGF_TMcD",
    "outputId": "860d0c42-0384-4202-ef8b-b8370ef7d46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11443a350>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* https://iksinc.online/tag/continuous-bag-of-words-cbow/\n",
    "* http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf\n",
    "* https://stackoverflow.com/questions/48479915/what-is-the-preferred-ratio-between-the-vocabulary-size-and-embedding-dimension\n",
    "* https://github.com/FraLotito/pytorch-continuous-bag-of-words/blob/master/cbow.py\n",
    "* https://stackoverflow.com/questions/50792316/what-does-1-mean-in-pytorch-view\n",
    "* https://www.tensorflow.org/tutorials/text/word_embeddings\n",
    "* https://pytorch.org/docs/stable/nn.html\n",
    "* https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "* https://github.com/ChristophAlt/embedding_vectorizer/blob/master/embedding_vectorizer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "class Vocabulary():\n",
    "    def __init__(self, filepath):\n",
    "        super(Vocabulary, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.tokens = self.nltk_tokenize()\n",
    "        self.tok_to_ids, self.ids_to_tok = self.make_dicts()\n",
    "    \n",
    "    def readfile(self):\n",
    "        \"\"\"this function opens the file and returns the text in a string\"\"\"\n",
    "        file = open(self.filepath)\n",
    "        text = file.read()\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub('SCENE \\S', '', text)\n",
    "        text = re.sub('(\\[_).*(_\\])', '', text)\n",
    "        text = re.sub(r'[\\\\[#$%*+—/<=>?{}|~@]+_', '', text)\n",
    "        text = text.lower()\n",
    "        file.close()\n",
    "        return text\n",
    "    \n",
    "    def nltk_tokenize(self):\n",
    "        \"\"\"this function tokenizes the text and returns a list of tokens as strings\"\"\"\n",
    "        text = self.readfile()\n",
    "        tokens = nltk.tokenize.word_tokenize(text)\n",
    "        return tokens\n",
    "    \n",
    "    def vocabulary_set(self):\n",
    "        \"\"\"this function returns a list of unique tokens\"\"\"\n",
    "        return(list(set(self.tokens)))\n",
    "    \n",
    "    def make_dicts(self):\n",
    "        unique_tokens = list(set(self.tokens))\n",
    "        tok_to_ix = {}\n",
    "        ix_to_tok = {}\n",
    "        for i in range(len(unique_tokens)):\n",
    "            tok_to_ix.update({unique_tokens[i]: i})\n",
    "            ix_to_tok.update({i: unique_tokens[i]})\n",
    "        return tok_to_ix, ix_to_tok\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tok_to_ids)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocab = vocabulary\n",
    "    \n",
    "    def vectorize(self, context_words):\n",
    "        context_ids = [self.vocab.tok_to_ids[w] for w in context_words]\n",
    "        return torch.tensor(context_ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, cbow_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cbow_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (Vectorizer): vectorizer instantiated from dataset\n",
    "        \"\"\"\n",
    "        self.cbow_df = cbow_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, cbow_df.context))\n",
    "        \n",
    "        self.train_df = self.cbow_df[self.cbow_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.cbow_df[self.cbow_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.cbow_df[self.cbow_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, cbow_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            cbow_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        cbow_df = pd.read_csv(cbow_csv)\n",
    "        train_cbow_df = cbow_df[cbow_df.split=='train']\n",
    "        return cls(cbow_df, CBOWVectorizer.from_dataframe(train_cbow_df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, cbow_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            cbow_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        cbow_df = pd.read_csv(cbow_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(cbow_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of CBOWVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return CBOWVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "        \n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        context_vector = \\\n",
    "            self._vectorizer.vectorize(row.context, self._max_seq_length)\n",
    "        target_index = self._vectorizer.cbow_vocab.lookup_token(row.target)\n",
    "\n",
    "        return {'x_data': context_vector,\n",
    "                'y_target': target_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "    \n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sub() missing 2 required positional arguments: 'repl' and 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-a5188a131a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_corpus.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Size of the context windows, 2 and 5 are supposed to be used in ex02...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-baaea97bd6a1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnltk_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_to_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids_to_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-baaea97bd6a1>\u001b[0m in \u001b[0;36mnltk_tokenize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnltk_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m\"\"\"this function tokenizes the text and returns a list of tokens as strings\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-baaea97bd6a1>\u001b[0m in \u001b[0;36mreadfile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SCENE \\S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(\\[_).*(_\\])'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[\\\\[#$%*+—/<=>?{}|~@]+_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sub() missing 2 required positional arguments: 'repl' and 'string'"
     ]
    }
   ],
   "source": [
    "filepath = 'test_corpus.txt'\n",
    "test_vocab = Vocabulary(filepath)\n",
    "vectorizer = Vectorizer(test_vocab)\n",
    "\n",
    "# Size of the context windows, 2 and 5 are supposed to be used in ex02...\n",
    "# range \\in [2, 1/2 * document_length - 1]\n",
    "CONTEXT_SIZE = 2\n",
    "\n",
    "# let's stick with this notation for now ;)\n",
    "CONTEXT_WINDOW_SIZE = CONTEXT_SIZE * 2\n",
    "\n",
    "\n",
    "# Data creation - get context around the target word\n",
    "data = []\n",
    "tokens = test_vocab.tokens\n",
    "for i in range(CONTEXT_SIZE, len(tokens) - CONTEXT_SIZE):\n",
    "    # Context before w_i\n",
    "    context_before_w = tokens[i - CONTEXT_SIZE: i]\n",
    "    \n",
    "    # Context after w_i\n",
    "    context_after_w = tokens[i + 1: i + CONTEXT_SIZE + 1]\n",
    "    \n",
    "    # Put them together\n",
    "    context_window = context_before_w + context_after_w\n",
    "    \n",
    "    # Target = w_i\n",
    "    target = tokens[i]\n",
    "    \n",
    "    # Append in the correct format\n",
    "    data.append((context_window, target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_window_size, nr_hidden_neurons=128):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.context_window_size = context_window_size\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # note: this probably doesn't deal with 'UNK' words\n",
    "        self.linear1 = nn.Linear(embedding_dim, nr_hidden_neurons)  \n",
    "        \n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(nr_hidden_neurons, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # shape = (WINDOW_SIZE, EMBEDDING_DIM) -> (EMBEDDING_DIM)\n",
    "        embeds = sum(self.embeddings(inputs))\n",
    "\n",
    "        # shape = (1, EMBEDDING_DIM)\n",
    "        # -1 param in view() ... \"the actual value for this dimension will be inferred so that the number of elements in the view matches the original number of elements.\"\n",
    "        embeds_2D = embeds.view(1, -1)\n",
    "        \n",
    "        # finally compute the hidden layer weighted sum (a.k.a. output before using the activation function)\n",
    "        # ... and don't forget to divide by the number of input vectors\n",
    "        h =  self.linear1(embeds_2D) / self.context_window_size\n",
    "        \n",
    "        # output of the hidden layer\n",
    "        out =  F.relu(h) \n",
    "         \n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.softmax(out, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.6298, -0.9274,  0.5451],\n",
      "        [ 0.0663, -0.4370,  0.7626,  ...,  1.1899,  0.8165, -0.9135],\n",
      "        [ 1.3851, -0.8138, -0.9276,  ...,  0.6419,  0.4730, -0.4286],\n",
      "        ...,\n",
      "        [ 1.2912,  0.8456,  0.0273,  ...,  0.5587,  1.5640, -0.2389],\n",
      "        [ 0.5841, -0.5436, -0.8403,  ...,  0.6580, -0.3210,  0.1259],\n",
      "        [ 0.6293,  0.1334, -0.5666,  ..., -0.2033,  0.6930, -1.6899]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:00<00:42,  2.32it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:43,  2.28it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:01<00:47,  2.06it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:02<00:47,  2.00it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:02<00:50,  1.87it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:03<00:49,  1.89it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:03<00:52,  1.78it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:04<00:49,  1.85it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:04<00:50,  1.82it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:05<00:51,  1.75it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:06<00:57,  1.55it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:06<00:54,  1.61it/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:07<00:53,  1.64it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:08<00:53,  1.62it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:08<00:53,  1.58it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:09<00:48,  1.72it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:09<00:46,  1.79it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:10<00:43,  1.88it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:10<00:42,  1.91it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:11<00:40,  1.96it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:11<00:40,  1.94it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:12<00:40,  1.91it/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:12<00:42,  1.79it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:13<00:44,  1.72it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:14<00:52,  1.42it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:15<00:53,  1.40it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:15<00:51,  1.43it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:16<00:54,  1.33it/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:17<00:57,  1.24it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:18<00:57,  1.23it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:19<00:58,  1.19it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:20<00:56,  1.21it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:21<00:55,  1.22it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:21<00:53,  1.23it/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:22<00:52,  1.24it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:23<00:52,  1.21it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:24<00:51,  1.23it/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:25<00:49,  1.25it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:25<00:47,  1.29it/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:26<00:44,  1.35it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:27<00:42,  1.38it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:27<00:41,  1.41it/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:28<00:39,  1.44it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:29<00:40,  1.39it/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:29<00:39,  1.41it/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:30<00:37,  1.44it/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:31<00:36,  1.47it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:31<00:34,  1.49it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:32<00:34,  1.50it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:33<00:33,  1.50it/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:33<00:34,  1.44it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:34<00:33,  1.44it/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:35<00:31,  1.47it/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:35<00:31,  1.48it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:36<00:29,  1.51it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:37<00:29,  1.51it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:37<00:28,  1.51it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:38<00:28,  1.49it/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:39<00:28,  1.46it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:40<00:27,  1.44it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:40<00:27,  1.44it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:41<00:26,  1.44it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:42<00:25,  1.47it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:42<00:24,  1.47it/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:43<00:23,  1.48it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:44<00:23,  1.48it/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:44<00:22,  1.49it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:45<00:21,  1.50it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:46<00:20,  1.49it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:46<00:20,  1.50it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:47<00:18,  1.53it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:48<00:18,  1.55it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:48<00:17,  1.54it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:49<00:16,  1.55it/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:50<00:16,  1.52it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:50<00:16,  1.49it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:51<00:15,  1.53it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:51<00:14,  1.52it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:52<00:14,  1.47it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:53<00:15,  1.31it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:54<00:14,  1.27it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:55<00:14,  1.26it/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:55<00:12,  1.32it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:56<00:12,  1.32it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:57<00:11,  1.36it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:58<00:09,  1.41it/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:58<00:08,  1.45it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:59<00:07,  1.50it/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [01:00<00:07,  1.38it/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [01:01<00:07,  1.34it/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [01:01<00:06,  1.34it/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [01:02<00:06,  1.20it/s]\u001b[A\n",
      " 93%|█████████▎| 93/100 [01:03<00:05,  1.27it/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [01:04<00:04,  1.31it/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [01:04<00:03,  1.37it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [01:05<00:02,  1.37it/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [01:06<00:02,  1.40it/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [01:06<00:01,  1.42it/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [01:07<00:00,  1.42it/s]\u001b[A\n",
      "100%|██████████| 100/100 [01:08<00:00,  1.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2155.269766330719, 2150.2176065444946, 2144.7264523506165, 2142.104751586914, 2134.9303426742554, 2132.871802330017, 2131.2438731193542, 2132.016471385956, 2130.2140889167786, 2130.689598083496, 2129.4444818496704, 2128.4260540008545, 2127.4395203590393, 2127.47371673584, 2128.14830827713, 2125.3561091423035, 2122.9606852531433, 2122.457365989685, 2120.665677547455, 2120.5340185165405, 2122.1506428718567, 2126.443124771118, 2124.3322806358337, 2120.45459651947, 2119.616554737091, 2120.538073539734, 2120.457799434662, 2121.0774002075195, 2121.4540977478027, 2121.457197189331, 2121.458430290222, 2121.453953742981, 2121.4563903808594, 2122.4190344810486, 2124.451714992523, 2123.4565138816833, 2126.9525747299194, 2126.1297359466553, 2122.44739484787, 2122.4575657844543, 2123.4552340507507, 2126.4520320892334, 2123.3524346351624, 2122.4566469192505, 2122.45352602005, 2123.4615893363953, 2122.4568815231323, 2122.457461833954, 2122.4605445861816, 2122.458227157593, 2122.456073284149, 2122.460949897766, 2122.4546427726746, 2124.4530277252197, 2129.3743171691895, 2129.4561247825623, 2129.456715106964, 2129.5844464302063, 2126.448495388031, 2126.466302394867, 2126.456545829773, 2126.4742817878723, 2127.452696323395, 2126.4982137680054, 2125.452766418457, 2129.4464225769043, 2128.4629073143005, 2129.456064224243, 2129.4579205513, 2129.454384803772, 2126.4587202072144, 2128.6209783554077, 2127.689287185669, 2128.458786010742, 2128.51695728302, 2127.461422920227, 2127.462411880493, 2127.462831020355, 2127.462987422943, 2127.462987422943, 2127.462987422943, 2127.462987422943, 2127.462986469269, 2127.462987422943, 2127.4629855155945, 2127.462987422943, 2127.462938308716, 2127.4616832733154, 2127.461361885071, 2130.456467628479, 2131.4629163742065, 2132.463231086731, 2130.463098526001, 2129.4606041908264, 2131.459303379059, 2132.461793899536, 2130.4609451293945, 2132.4622049331665, 2131.462902545929, 2136.459686756134]\n",
      "Parameter containing:\n",
      "tensor([[-1.4999, -0.8250, -0.6680,  ..., -0.2541, -1.0478,  0.3321],\n",
      "        [ 0.1152, -0.4888,  0.9708,  ...,  0.3261,  0.4243, -2.0834],\n",
      "        [ 0.1265, -0.3572,  0.1615,  ...,  0.1056,  1.5786, -0.9895],\n",
      "        ...,\n",
      "        [ 1.9575,  0.6580,  0.9482,  ..., -0.3270,  0.8082, -0.4280],\n",
      "        [ 0.4744, -0.8893, -0.1623,  ...,  1.9224, -0.5748,  1.3261],\n",
      "        [ 0.8404,  0.2384, -0.5634,  ...,  1.5984,  1.1679, -0.7576]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS = 100\n",
    "NUM_NEURONS = 100\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "model = CBOW(len(test_vocab), EMBEDDING_DIM, CONTEXT_WINDOW_SIZE, NUM_NEURONS)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model.embeddings.weight)\n",
    "\n",
    "for epoch in tqdm(range(NUM_ITERATIONS)):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        # Step1. Create input vector \n",
    "        context_vector_ids = vectorizer.vectorize(context)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        softmax = model(context_vector_ids)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        target = torch.tensor(vectorizer.vocab.tok_to_ids[target], dtype=torch.long).view(1)\n",
    "        loss = loss_function(softmax, target)\n",
    "        \n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(losses)\n",
    "print(model.embeddings.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## OOP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shakespeare_csv_filepath = 'test_corpus.txt'\n",
    "#dataset = ShakespeareDataset.load_dataset_and_make_vectorizer(shakespeare_csv_filepath)\n",
    "#dataset.save_vectorizer(args.vectorizer_file)\n",
    "    \n",
    "#vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "#classifier = CBOWClassifier(vocabulary_size=len(vectorizer.cbow_vocab), embedding_size=args.embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Test your embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('die', 7.657770156860352),\n",
       " ('How', 9.359249114990234),\n",
       " ('Were', 9.374570846557617),\n",
       " ('only', 9.418946266174316),\n",
       " ('say', 9.439167976379395)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part2 supplied function\n",
    "def get_closest_word(word, topn=5):\n",
    "    word_distance = []\n",
    "    emb = model.embeddings\n",
    "    pdist = nn.PairwiseDistance()\n",
    "    i = test_vocab.tok_to_ids[word]\n",
    "    lookup_tensor_i = torch.tensor([i], dtype=torch.long) \n",
    "    v_i = emb(lookup_tensor_i)\n",
    "    for j in range(len(test_vocab)): \n",
    "        if j != i:\n",
    "            lookup_tensor_j = torch.tensor([j], dtype=torch.long)\n",
    "            v_j = emb(lookup_tensor_j) \n",
    "            word_distance.append((test_vocab.ids_to_tok[j], float(pdist(v_i, v_j))))\n",
    "    word_distance.sort(key=lambda x: x[1]) \n",
    "    return word_distance[:topn]\n",
    "\n",
    "get_closest_word('that')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1882640586797066\n",
      "0.9999999992713369\n"
     ]
    }
   ],
   "source": [
    "nr_examples = len(data)\n",
    "pred_sum = 0 # softmax check\n",
    "acc_sum = 0 # accuracy\n",
    "\n",
    "for i in range(nr_examples):\n",
    "    ids = vectorizer.vectorize(data[i][0])\n",
    "    target = test_vocab.tok_to_ids[data[i][1]]\n",
    "    pred = model(ids) # prediction\n",
    "    pred_sum += pred.squeeze().sum().item() \n",
    "    \n",
    "    _, pred_indices = pred.max(dim=1) # prediction index\n",
    "    n_correct = torch.eq(pred_indices, target)\n",
    "    acc_sum += n_correct.item()\n",
    "    \n",
    "print(acc_sum / nr_examples)\n",
    "print(pred_sum / nr_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is an \n"
     ]
    }
   ],
   "source": [
    "stringo = \"here is an [_exit_]\"\n",
    "stringo = re.sub('(\\[_).*(_\\])', '', stringo)\n",
    "print(stringo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finis is 164924\n",
    "#beginngin is line 134 --> just keep what's in between those lines\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of word_embeddings_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
