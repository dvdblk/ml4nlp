{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DQTQQGF_TMcD",
    "outputId": "860d0c42-0384-4202-ef8b-b8370ef7d46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11443a350>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* https://iksinc.online/tag/continuous-bag-of-words-cbow/\n",
    "* http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf\n",
    "* https://stackoverflow.com/questions/48479915/what-is-the-preferred-ratio-between-the-vocabulary-size-and-embedding-dimension\n",
    "* https://github.com/FraLotito/pytorch-continuous-bag-of-words/blob/master/cbow.py\n",
    "* https://stackoverflow.com/questions/50792316/what-does-1-mean-in-pytorch-view\n",
    "* https://www.tensorflow.org/tutorials/text/word_embeddings\n",
    "* https://pytorch.org/docs/stable/nn.html\n",
    "* https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "* https://github.com/ChristophAlt/embedding_vectorizer/blob/master/embedding_vectorizer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "class Vocabulary():\n",
    "    def __init__(self, filepath):\n",
    "        super(Vocabulary, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.tokens = self.nltk_tokenize()\n",
    "        self.tok_to_ids, self.ids_to_tok = self.make_dicts()\n",
    "    \n",
    "    def readfile(self):\n",
    "        \"\"\"this function opens the file and returns the text in a string\"\"\"\n",
    "        file = open(self.filepath)\n",
    "        lines = file.readlines()\n",
    "        #lines = lines[134:164924] #these numbers are only valid for the full corpus\n",
    "        text = ''.join(lines)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub('SCENE \\S', '', text)\n",
    "        text = re.sub('(\\[_).*(_\\])', '', text)\n",
    "        text = re.sub(r'[\\\\[#$%*+—/<=>?{}|~@]+_', '', text)\n",
    "        text = text.lower()\n",
    "        file.close()\n",
    "        return text\n",
    "    \n",
    "    def nltk_tokenize(self):\n",
    "        \"\"\"this function tokenizes the text and returns a list of tokens as strings\"\"\"\n",
    "        text = self.readfile()\n",
    "        tokens = nltk.tokenize.word_tokenize(text)\n",
    "        return tokens\n",
    "    \n",
    "    def vocabulary_set(self):\n",
    "        \"\"\"this function returns a list of unique tokens\"\"\"\n",
    "        return(list(set(self.tokens)))\n",
    "    \n",
    "    def make_dicts(self):\n",
    "        unique_tokens = list(set(self.tokens))\n",
    "        tok_to_ix = {}\n",
    "        ix_to_tok = {}\n",
    "        for i in range(len(unique_tokens)):\n",
    "            tok_to_ix.update({unique_tokens[i]: i})\n",
    "            ix_to_tok.update({i: unique_tokens[i]})\n",
    "        return tok_to_ix, ix_to_tok\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tok_to_ids)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocab = vocabulary\n",
    "    \n",
    "    def vectorize(self, context_words):\n",
    "        context_ids = [self.vocab.tok_to_ids[w] for w in context_words]\n",
    "        return torch.tensor(context_ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, cbow_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cbow_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (Vectorizer): vectorizer instantiated from dataset\n",
    "        \"\"\"\n",
    "        self.cbow_df = cbow_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, cbow_df.context))\n",
    "        \n",
    "        self.train_df = self.cbow_df[self.cbow_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.cbow_df[self.cbow_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.cbow_df[self.cbow_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, cbow_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            cbow_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        cbow_df = pd.read_csv(cbow_csv)\n",
    "        train_cbow_df = cbow_df[cbow_df.split=='train']\n",
    "        return cls(cbow_df, CBOWVectorizer.from_dataframe(train_cbow_df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, cbow_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            cbow_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        cbow_df = pd.read_csv(cbow_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(cbow_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of CBOWVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return CBOWVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "        \n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        context_vector = \\\n",
    "            self._vectorizer.vectorize(row.context, self._max_seq_length)\n",
    "        target_index = self._vectorizer.cbow_vocab.lookup_token(row.target)\n",
    "\n",
    "        return {'x_data': context_vector,\n",
    "                'y_target': target_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "    \n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'test_corpus.txt'\n",
    "test_vocab = Vocabulary(filepath)\n",
    "vectorizer = Vectorizer(test_vocab)\n",
    "\n",
    "# Size of the context windows, 2 and 5 are supposed to be used in ex02...\n",
    "# range \\in [2, 1/2 * document_length - 1]\n",
    "CONTEXT_SIZE = 2\n",
    "\n",
    "# let's stick with this notation for now ;)\n",
    "CONTEXT_WINDOW_SIZE = CONTEXT_SIZE * 2\n",
    "\n",
    "\n",
    "# Data creation - get context around the target word\n",
    "data = []\n",
    "tokens = test_vocab.tokens\n",
    "for i in range(CONTEXT_SIZE, len(tokens) - CONTEXT_SIZE):\n",
    "    # Context before w_i\n",
    "    context_before_w = tokens[i - CONTEXT_SIZE: i]\n",
    "    \n",
    "    # Context after w_i\n",
    "    context_after_w = tokens[i + 1: i + CONTEXT_SIZE + 1]\n",
    "    \n",
    "    # Put them together\n",
    "    context_window = context_before_w + context_after_w\n",
    "    \n",
    "    # Target = w_i\n",
    "    target = tokens[i]\n",
    "    \n",
    "    # Append in the correct format\n",
    "    data.append((context_window, target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_window_size, nr_hidden_neurons=128):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.context_window_size = context_window_size\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # note: this probably doesn't deal with 'UNK' words\n",
    "        self.linear1 = nn.Linear(embedding_dim, nr_hidden_neurons)  \n",
    "        \n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(nr_hidden_neurons, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # shape = (WINDOW_SIZE, EMBEDDING_DIM) -> (EMBEDDING_DIM)\n",
    "        embeds = sum(self.embeddings(inputs))\n",
    "\n",
    "        # shape = (1, EMBEDDING_DIM)\n",
    "        # -1 param in view() ... \"the actual value for this dimension will be inferred so that the number of elements in the view matches the original number of elements.\"\n",
    "        embeds_2D = embeds.view(1, -1)\n",
    "        \n",
    "        # finally compute the hidden layer weighted sum (a.k.a. output before using the activation function)\n",
    "        # ... and don't forget to divide by the number of input vectors\n",
    "        h =  self.linear1(embeds_2D) / self.context_window_size\n",
    "        \n",
    "        # output of the hidden layer\n",
    "        out =  F.relu(h) \n",
    "         \n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.softmax(out, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.6298, -0.9274,  0.5451],\n",
      "        [ 0.0663, -0.4370,  0.7626,  ...,  1.1899,  0.8165, -0.9135],\n",
      "        [ 1.3851, -0.8138, -0.9276,  ...,  0.6419,  0.4730, -0.4286],\n",
      "        ...,\n",
      "        [ 0.2124,  0.9873, -0.2969,  ..., -2.1730,  0.1277, -1.1812],\n",
      "        [ 0.0054, -0.3642,  0.4567,  ..., -1.5041, -0.7924,  0.0683],\n",
      "        [ 1.0057,  0.0652,  1.9921,  ...,  0.4940,  1.0178,  0.2038]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:00<00:35,  2.76it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:35,  2.78it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:01<00:36,  2.69it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:01<00:35,  2.74it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:01<00:33,  2.81it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:02<00:34,  2.73it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:02<00:33,  2.76it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:02<00:34,  2.67it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:03<00:34,  2.67it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:03<00:33,  2.71it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:04<00:33,  2.64it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:04<00:32,  2.67it/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:04<00:32,  2.69it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:05<00:33,  2.60it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:05<00:32,  2.61it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:06<00:32,  2.55it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:06<00:31,  2.62it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:06<00:31,  2.62it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:07<00:31,  2.55it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:07<00:33,  2.41it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:08<00:35,  2.21it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:08<00:41,  1.89it/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:10<00:54,  1.41it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:10<00:48,  1.57it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:11<00:45,  1.64it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:11<00:42,  1.74it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:12<00:41,  1.74it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:12<00:39,  1.81it/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:13<00:39,  1.82it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:13<00:38,  1.83it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:14<00:37,  1.82it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:14<00:36,  1.85it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:15<00:36,  1.84it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:15<00:37,  1.76it/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:16<00:37,  1.74it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:17<00:38,  1.68it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:17<00:37,  1.69it/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:18<00:40,  1.55it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:19<00:39,  1.53it/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:19<00:38,  1.56it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:20<00:38,  1.52it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:21<00:39,  1.48it/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:21<00:37,  1.52it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:22<00:36,  1.54it/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:23<00:35,  1.56it/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:23<00:33,  1.61it/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:24<00:32,  1.64it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:24<00:30,  1.71it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:25<00:29,  1.72it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:25<00:28,  1.76it/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:26<00:28,  1.74it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:27<00:27,  1.72it/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:27<00:26,  1.75it/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:28<00:26,  1.74it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:28<00:25,  1.78it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:29<00:24,  1.77it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:29<00:23,  1.82it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:30<00:23,  1.78it/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:30<00:23,  1.77it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:31<00:22,  1.77it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:32<00:23,  1.68it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:32<00:22,  1.73it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:33<00:22,  1.65it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:34<00:21,  1.65it/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:34<00:21,  1.64it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:35<00:21,  1.57it/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:35<00:20,  1.64it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:36<00:19,  1.68it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:37<00:18,  1.67it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:37<00:18,  1.65it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:38<00:17,  1.66it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:38<00:16,  1.74it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:39<00:15,  1.77it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:39<00:14,  1.82it/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:40<00:13,  1.84it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:40<00:12,  1.88it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:41<00:12,  1.87it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:41<00:11,  1.92it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:42<00:11,  1.88it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:42<00:10,  1.89it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:43<00:10,  1.87it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:44<00:10,  1.80it/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:44<00:10,  1.64it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:46<00:15,  1.05it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:47<00:12,  1.19it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:47<00:10,  1.35it/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:48<00:08,  1.49it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:48<00:07,  1.62it/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [00:49<00:06,  1.70it/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [00:49<00:05,  1.75it/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [00:50<00:05,  1.79it/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [00:50<00:04,  1.82it/s]\u001b[A\n",
      " 93%|█████████▎| 93/100 [00:51<00:03,  1.79it/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [00:51<00:03,  1.78it/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [00:52<00:02,  1.79it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:53<00:02,  1.79it/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [00:53<00:01,  1.81it/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [00:54<00:01,  1.81it/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [00:54<00:00,  1.81it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:55<00:00,  1.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2137.0678267478943, 2124.274205684662, 2121.040813446045, 2111.0573649406433, 2107.6739778518677, 2108.5109457969666, 2108.5132751464844, 2102.539351463318, 2106.4591636657715, 2102.3065090179443, 2105.758240699768, 2104.2444472312927, 2096.718550682068, 2093.114233970642, 2091.3732018470764, 2094.2937202453613, 2092.539632797241, 2092.5157675743103, 2091.380917072296, 2093.526613712311, 2095.473023414612, 2091.632371902466, 2088.8245248794556, 2094.1868958473206, 2087.564106941223, 2087.538487434387, 2086.2816591262817, 2087.015751361847, 2086.5449895858765, 2086.552490711212, 2085.7277884483337, 2088.77752161026, 2089.54544878006, 2089.5604429244995, 2089.5518498420715, 2089.559072494507, 2089.5588278770447, 2089.5594487190247, 2090.5582280158997, 2088.5690383911133, 2089.957133769989, 2088.552963733673, 2088.552481651306, 2089.4736919403076, 2089.5250549316406, 2088.1021733283997, 2087.542254447937, 2086.548861503601, 2086.528482913971, 2086.5507249832153, 2086.502411842346, 2086.5561442375183, 2088.509536266327, 2086.5524644851685, 2086.557270526886, 2086.5605702400208, 2087.2326402664185, 2087.2938475608826, 2086.746029853821, 2088.5491213798523, 2086.556101322174, 2086.549117088318, 2085.562077522278, 2085.5574884414673, 2085.604805469513, 2087.559814453125, 2087.5588006973267, 2087.553538799286, 2088.5593962669373, 2086.557508468628, 2086.5601115226746, 2086.5574016571045, 2087.5616416931152, 2087.6592206954956, 2086.5539875030518, 2086.557535171509, 2086.5569500923157, 2086.0838742256165, 2085.5603499412537, 2085.55889749527, 2085.555401802063, 2088.558678627014, 2087.559628009796, 2088.761923789978, 2086.5600209236145, 2085.5534296035767, 2088.5530610084534, 2084.5568447113037, 2084.5535464286804, 2085.5596170425415, 2084.5605149269104, 2083.5620913505554, 2084.5606203079224, 2084.5596194267273, 2084.559410095215, 2084.5539202690125, 2083.6041860580444, 2083.5578236579895, 2085.5580430030823, 2086.559319496155]\n",
      "Parameter containing:\n",
      "tensor([[-1.5683, -0.1145,  0.0943,  ..., -1.9266, -0.3543,  0.6949],\n",
      "        [-1.7674, -2.1331,  0.0135,  ...,  1.5794, -0.0328, -2.6805],\n",
      "        [ 1.2448, -0.7102, -2.0891,  ...,  0.9844, -0.1875,  0.3229],\n",
      "        ...,\n",
      "        [ 1.5152,  0.6443,  1.0217,  ..., -3.0064,  0.3465, -0.9892],\n",
      "        [-1.2499, -0.3580, -1.0158,  ..., -2.9348, -0.3945, -1.2964],\n",
      "        [-0.0466, -0.0747,  1.2364,  ...,  0.1275,  0.9986, -0.2323]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS = 100\n",
    "NUM_NEURONS = 100\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "model = CBOW(len(test_vocab), EMBEDDING_DIM, CONTEXT_WINDOW_SIZE, NUM_NEURONS)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model.embeddings.weight)\n",
    "\n",
    "for epoch in tqdm(range(NUM_ITERATIONS)):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        # Step1. Create input vector \n",
    "        context_vector_ids = vectorizer.vectorize(context)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        softmax = model(context_vector_ids)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        target = torch.tensor(vectorizer.vocab.tok_to_ids[target], dtype=torch.long).view(1)\n",
    "        loss = loss_function(softmax, target)\n",
    "        \n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(losses)\n",
    "print(model.embeddings.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## OOP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shakespeare_csv_filepath = 'test_corpus.txt'\n",
    "#dataset = ShakespeareDataset.load_dataset_and_make_vectorizer(shakespeare_csv_filepath)\n",
    "#dataset.save_vectorizer(args.vectorizer_file)\n",
    "    \n",
    "#vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "#classifier = CBOWClassifier(vocabulary_size=len(vectorizer.cbow_vocab), embedding_size=args.embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Test your embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uneared', 8.883015632629395),\n",
       " ('gaudy', 9.166439056396484),\n",
       " ('by', 9.197699546813965),\n",
       " ('viewest', 9.315560340881348),\n",
       " ('another', 9.614222526550293)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part2 supplied function\n",
    "def get_closest_word(word, topn=5):\n",
    "    word_distance = []\n",
    "    emb = model.embeddings\n",
    "    pdist = nn.PairwiseDistance()\n",
    "    i = test_vocab.tok_to_ids[word]\n",
    "    lookup_tensor_i = torch.tensor([i], dtype=torch.long) \n",
    "    v_i = emb(lookup_tensor_i)\n",
    "    for j in range(len(test_vocab)): \n",
    "        if j != i:\n",
    "            lookup_tensor_j = torch.tensor([j], dtype=torch.long)\n",
    "            v_j = emb(lookup_tensor_j) \n",
    "            word_distance.append((test_vocab.ids_to_tok[j], float(pdist(v_i, v_j))))\n",
    "    word_distance.sort(key=lambda x: x[1]) \n",
    "    return word_distance[:topn]\n",
    "\n",
    "get_closest_word('desire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1330049261083744\n",
      "0.9999999994127621\n"
     ]
    }
   ],
   "source": [
    "nr_examples = len(data)\n",
    "pred_sum = 0 # softmax check\n",
    "acc_sum = 0 # accuracy\n",
    "\n",
    "for i in range(nr_examples):\n",
    "    ids = vectorizer.vectorize(data[i][0])\n",
    "    target = test_vocab.tok_to_ids[data[i][1]]\n",
    "    pred = model(ids) # prediction\n",
    "    pred_sum += pred.squeeze().sum().item() \n",
    "    \n",
    "    _, pred_indices = pred.max(dim=1) # prediction index\n",
    "    n_correct = torch.eq(pred_indices, target)\n",
    "    acc_sum += n_correct.item()\n",
    "    \n",
    "print(acc_sum / nr_examples)\n",
    "print(pred_sum / nr_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is an \n"
     ]
    }
   ],
   "source": [
    "stringo = \"here is an [_exit_]\"\n",
    "stringo = re.sub('(\\[_).*(_\\])', '', stringo)\n",
    "print(stringo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finis is 164924\n",
    "#beginngin is line 134 --> just keep what's in between those lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'shakespeare-corpus.txt'\n",
    "file = open(filename)\n",
    "lines = file.readlines()\n",
    "lines = lines[134:164924]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 17.7 ms, total: 1.03 s\n",
      "Wall time: 1.08 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5521081"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mytext(lines):\n",
    "    corpus = ''\n",
    "    for line in lines:\n",
    "        text = re.sub(r'\\d+', '', line)\n",
    "        text = re.sub('SCENE \\S', '', text)\n",
    "        text = re.sub('(\\[_).*(_\\])', '', text)\n",
    "        text = re.sub(r'[\\\\[#$%*+—/<=>?{}|~@]+_', '', text)\n",
    "        text = text.lower()\n",
    "        corpus += text\n",
    "    return corpus\n",
    "\n",
    "%time len(mytext(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 294 ms, sys: 20.7 ms, total: 315 ms\n",
      "Wall time: 330 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5521081"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mytext2(lines):\n",
    "    text = ''.join(lines)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub('SCENE \\S', '', text)\n",
    "    text = re.sub('(\\[_).*(_\\])', '', text)\n",
    "    text = re.sub(r'[\\\\[#$%*+—/<=>?{}|~@]+_', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "%time len(mytext2(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of word_embeddings_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
